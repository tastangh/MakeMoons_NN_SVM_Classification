2024-12-20 15:57:39,921 [INFO]: Trainer initialized.
2024-12-20 15:57:39,921 [INFO]: Creating and splitting the dataset...
2024-12-20 15:57:39,925 [INFO]: Visualizing the dataset...
2024-12-20 15:57:40,471 [INFO]: Data preparation complete.
2024-12-20 15:57:40,471 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=SGD, Layers=1...
2024-12-20 15:57:40,929 [INFO]: Epoch 1/50: loss: 0.7243, accuracy: 0.5000, val_loss: 0.7387, val_accuracy: 0.4625
2024-12-20 15:57:49,392 [INFO]: Epoch 50/50: loss: 0.6770, accuracy: 0.6250, val_loss: 0.6764, val_accuracy: 0.5875
2024-12-20 15:57:50,542 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=SGD, Layers=2...
2024-12-20 15:57:50,974 [INFO]: Epoch 1/50: loss: 0.7752, accuracy: 0.5000, val_loss: 0.7400, val_accuracy: 0.5375
2024-12-20 15:57:59,213 [INFO]: Epoch 50/50: loss: 0.6869, accuracy: 0.6500, val_loss: 0.6852, val_accuracy: 0.6625
2024-12-20 15:58:00,273 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=SGD, Layers=3...
2024-12-20 15:58:00,730 [INFO]: Epoch 1/50: loss: 0.7064, accuracy: 0.5000, val_loss: 0.6938, val_accuracy: 0.5375
2024-12-20 15:58:09,093 [INFO]: Epoch 50/50: loss: 0.6933, accuracy: 0.4958, val_loss: 0.6928, val_accuracy: 0.5375
2024-12-20 15:58:10,200 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=BGD, Layers=1...
2024-12-20 15:58:10,475 [INFO]: Epoch 1/50: loss: 0.9952, accuracy: 0.5000, val_loss: 0.9337, val_accuracy: 0.5375
2024-12-20 15:58:12,141 [INFO]: Epoch 50/50: loss: 0.9903, accuracy: 0.5000, val_loss: 0.9293, val_accuracy: 0.5375
2024-12-20 15:58:13,181 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=BGD, Layers=2...
2024-12-20 15:58:13,472 [INFO]: Epoch 1/50: loss: 0.8428, accuracy: 0.5000, val_loss: 0.8014, val_accuracy: 0.5375
2024-12-20 15:58:15,132 [INFO]: Epoch 50/50: loss: 0.8400, accuracy: 0.5000, val_loss: 0.7990, val_accuracy: 0.5375
2024-12-20 15:58:16,325 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=BGD, Layers=3...
2024-12-20 15:58:16,647 [INFO]: Epoch 1/50: loss: 0.8134, accuracy: 0.5000, val_loss: 0.7758, val_accuracy: 0.5375
2024-12-20 15:58:18,326 [INFO]: Epoch 50/50: loss: 0.8104, accuracy: 0.5000, val_loss: 0.7733, val_accuracy: 0.5375
2024-12-20 15:58:19,397 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=MBGD, Layers=1...
2024-12-20 15:58:19,715 [INFO]: Epoch 1/50: loss: 0.7150, accuracy: 0.5000, val_loss: 0.7347, val_accuracy: 0.4625
2024-12-20 15:58:21,666 [INFO]: Epoch 50/50: loss: 0.7079, accuracy: 0.5000, val_loss: 0.7257, val_accuracy: 0.4625
2024-12-20 15:58:22,717 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=MBGD, Layers=2...
2024-12-20 15:58:23,049 [INFO]: Epoch 1/50: loss: 0.7757, accuracy: 0.5000, val_loss: 0.8054, val_accuracy: 0.4625
2024-12-20 15:58:25,006 [INFO]: Epoch 50/50: loss: 0.7620, accuracy: 0.5000, val_loss: 0.7887, val_accuracy: 0.4625
2024-12-20 15:58:26,064 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=MBGD, Layers=3...
2024-12-20 15:58:26,424 [INFO]: Epoch 1/50: loss: 0.6928, accuracy: 0.5000, val_loss: 0.6938, val_accuracy: 0.4625
2024-12-20 15:58:28,391 [INFO]: Epoch 50/50: loss: 0.6928, accuracy: 0.5000, val_loss: 0.6937, val_accuracy: 0.4625
2024-12-20 15:58:29,459 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=SGD, Layers=1...
2024-12-20 15:58:29,866 [INFO]: Epoch 1/250: loss: 0.8218, accuracy: 0.5000, val_loss: 0.7861, val_accuracy: 0.5375
2024-12-20 15:59:11,015 [INFO]: Epoch 250/250: loss: 0.6064, accuracy: 0.7542, val_loss: 0.6036, val_accuracy: 0.7875
2024-12-20 15:59:12,043 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=SGD, Layers=2...
2024-12-20 15:59:12,473 [INFO]: Epoch 1/250: loss: 0.7374, accuracy: 0.5000, val_loss: 0.7564, val_accuracy: 0.4625
2024-12-20 15:59:54,321 [INFO]: Epoch 250/250: loss: 0.6759, accuracy: 0.7417, val_loss: 0.6752, val_accuracy: 0.7875
2024-12-20 15:59:55,390 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=SGD, Layers=3...
2024-12-20 15:59:55,845 [INFO]: Epoch 1/250: loss: 0.6967, accuracy: 0.5000, val_loss: 0.7034, val_accuracy: 0.4625
2024-12-20 16:00:38,051 [INFO]: Epoch 250/250: loss: 0.6904, accuracy: 0.8458, val_loss: 0.6901, val_accuracy: 0.8750
2024-12-20 16:00:39,133 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=BGD, Layers=1...
2024-12-20 16:00:39,565 [INFO]: Epoch 1/250: loss: 0.7465, accuracy: 0.5000, val_loss: 0.7705, val_accuracy: 0.4625
2024-12-20 16:00:48,096 [INFO]: Epoch 250/250: loss: 0.7408, accuracy: 0.5000, val_loss: 0.7635, val_accuracy: 0.4625
2024-12-20 16:00:49,161 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=BGD, Layers=2...
2024-12-20 16:00:49,456 [INFO]: Epoch 1/250: loss: 0.7144, accuracy: 0.5000, val_loss: 0.6999, val_accuracy: 0.5375
2024-12-20 16:00:57,971 [INFO]: Epoch 250/250: loss: 0.7120, accuracy: 0.5000, val_loss: 0.6984, val_accuracy: 0.5375
2024-12-20 16:00:59,027 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=BGD, Layers=3...
2024-12-20 16:00:59,351 [INFO]: Epoch 1/250: loss: 0.6929, accuracy: 0.5000, val_loss: 0.6985, val_accuracy: 0.4625
2024-12-20 16:01:07,848 [INFO]: Epoch 250/250: loss: 0.6926, accuracy: 0.5000, val_loss: 0.6978, val_accuracy: 0.4625
2024-12-20 16:01:08,943 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=MBGD, Layers=1...
2024-12-20 16:01:09,256 [INFO]: Epoch 1/250: loss: 0.8096, accuracy: 0.5000, val_loss: 0.7737, val_accuracy: 0.5375
2024-12-20 16:01:19,152 [INFO]: Epoch 250/250: loss: 0.7409, accuracy: 0.5000, val_loss: 0.7172, val_accuracy: 0.5375
2024-12-20 16:01:20,186 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=MBGD, Layers=2...
2024-12-20 16:01:20,520 [INFO]: Epoch 1/250: loss: 0.8052, accuracy: 0.5000, val_loss: 0.7699, val_accuracy: 0.5375
2024-12-20 16:01:30,451 [INFO]: Epoch 250/250: loss: 0.7441, accuracy: 0.5000, val_loss: 0.7216, val_accuracy: 0.5375
2024-12-20 16:01:31,514 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=MBGD, Layers=3...
2024-12-20 16:01:31,872 [INFO]: Epoch 1/250: loss: 0.7336, accuracy: 0.5000, val_loss: 0.7119, val_accuracy: 0.5375
2024-12-20 16:01:41,836 [INFO]: Epoch 250/250: loss: 0.7071, accuracy: 0.5000, val_loss: 0.6941, val_accuracy: 0.5375
2024-12-20 16:01:42,900 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=SGD, Layers=1...
2024-12-20 16:01:43,303 [INFO]: Epoch 1/500: loss: 0.7338, accuracy: 0.5000, val_loss: 0.7184, val_accuracy: 0.5375
2024-12-20 16:03:05,759 [INFO]: Epoch 500/500: loss: 0.5277, accuracy: 0.7958, val_loss: 0.5232, val_accuracy: 0.8000
2024-12-20 16:03:06,797 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=SGD, Layers=2...
2024-12-20 16:03:07,222 [INFO]: Epoch 1/500: loss: 0.8027, accuracy: 0.5000, val_loss: 0.8319, val_accuracy: 0.4625
2024-12-20 16:04:30,820 [INFO]: Epoch 500/500: loss: 0.6668, accuracy: 0.7750, val_loss: 0.6661, val_accuracy: 0.8000
2024-12-20 16:04:32,049 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=SGD, Layers=3...
2024-12-20 16:04:32,525 [INFO]: Epoch 1/500: loss: 0.7187, accuracy: 0.5000, val_loss: 0.7337, val_accuracy: 0.4625
2024-12-20 16:05:58,296 [INFO]: Epoch 500/500: loss: 0.6892, accuracy: 0.7833, val_loss: 0.6890, val_accuracy: 0.8000
2024-12-20 16:05:59,376 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=BGD, Layers=1...
2024-12-20 16:05:59,650 [INFO]: Epoch 1/500: loss: 0.7527, accuracy: 0.5000, val_loss: 0.7801, val_accuracy: 0.4625
2024-12-20 16:06:16,733 [INFO]: Epoch 500/500: loss: 0.7361, accuracy: 0.5000, val_loss: 0.7606, val_accuracy: 0.4625
2024-12-20 16:06:17,788 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=BGD, Layers=2...
2024-12-20 16:06:18,085 [INFO]: Epoch 1/500: loss: 0.7023, accuracy: 0.5000, val_loss: 0.6924, val_accuracy: 0.5375
2024-12-20 16:06:35,106 [INFO]: Epoch 500/500: loss: 0.7002, accuracy: 0.5000, val_loss: 0.6915, val_accuracy: 0.5375
2024-12-20 16:06:36,154 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=BGD, Layers=3...
2024-12-20 16:06:36,474 [INFO]: Epoch 1/500: loss: 0.7139, accuracy: 0.5000, val_loss: 0.7286, val_accuracy: 0.4625
2024-12-20 16:06:53,450 [INFO]: Epoch 500/500: loss: 0.7096, accuracy: 0.5000, val_loss: 0.7225, val_accuracy: 0.4625
2024-12-20 16:06:54,534 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=MBGD, Layers=1...
2024-12-20 16:06:54,844 [INFO]: Epoch 1/500: loss: 0.7261, accuracy: 0.2583, val_loss: 0.7301, val_accuracy: 0.2375
2024-12-20 16:07:14,641 [INFO]: Epoch 500/500: loss: 0.7147, accuracy: 0.2083, val_loss: 0.7163, val_accuracy: 0.2125
2024-12-20 16:07:15,700 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=MBGD, Layers=2...
2024-12-20 16:07:16,036 [INFO]: Epoch 1/500: loss: 0.7481, accuracy: 0.5000, val_loss: 0.7724, val_accuracy: 0.4625
2024-12-20 16:07:35,848 [INFO]: Epoch 500/500: loss: 0.7045, accuracy: 0.5000, val_loss: 0.7122, val_accuracy: 0.4625
2024-12-20 16:07:36,910 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=MBGD, Layers=3...
2024-12-20 16:07:37,268 [INFO]: Epoch 1/500: loss: 0.7055, accuracy: 0.5000, val_loss: 0.6944, val_accuracy: 0.5375
2024-12-20 16:07:57,119 [INFO]: Epoch 500/500: loss: 0.6964, accuracy: 0.5000, val_loss: 0.6919, val_accuracy: 0.5375
2024-12-20 16:07:58,176 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=SGD, Layers=1...
2024-12-20 16:07:58,769 [INFO]: Epoch 1/1000: loss: 0.7673, accuracy: 0.2292, val_loss: 0.7744, val_accuracy: 0.2375
2024-12-20 16:10:44,827 [INFO]: Epoch 1000/1000: loss: 0.3954, accuracy: 0.8250, val_loss: 0.3964, val_accuracy: 0.8125
2024-12-20 16:10:45,889 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=SGD, Layers=2...
2024-12-20 16:10:46,335 [INFO]: Epoch 1/1000: loss: 0.7048, accuracy: 0.5000, val_loss: 0.6941, val_accuracy: 0.5375
2024-12-20 16:13:35,770 [INFO]: Epoch 1000/1000: loss: 0.6082, accuracy: 0.7583, val_loss: 0.6055, val_accuracy: 0.7875
2024-12-20 16:13:36,850 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=SGD, Layers=3...
2024-12-20 16:13:37,316 [INFO]: Epoch 1/1000: loss: 0.7055, accuracy: 0.5000, val_loss: 0.7160, val_accuracy: 0.4625
2024-12-20 16:16:28,849 [INFO]: Epoch 1000/1000: loss: 0.6886, accuracy: 0.7417, val_loss: 0.6883, val_accuracy: 0.7750
2024-12-20 16:16:29,951 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=BGD, Layers=1...
2024-12-20 16:16:30,226 [INFO]: Epoch 1/1000: loss: 0.7475, accuracy: 0.5000, val_loss: 0.7269, val_accuracy: 0.5375
2024-12-20 16:17:04,230 [INFO]: Epoch 1000/1000: loss: 0.7340, accuracy: 0.5000, val_loss: 0.7174, val_accuracy: 0.5375
2024-12-20 16:17:05,288 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=BGD, Layers=2...
2024-12-20 16:17:05,586 [INFO]: Epoch 1/1000: loss: 0.7081, accuracy: 0.5000, val_loss: 0.6964, val_accuracy: 0.5375
2024-12-20 16:17:39,456 [INFO]: Epoch 1000/1000: loss: 0.7031, accuracy: 0.5000, val_loss: 0.6940, val_accuracy: 0.5375
2024-12-20 16:17:40,520 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=BGD, Layers=3...
2024-12-20 16:17:40,832 [INFO]: Epoch 1/1000: loss: 0.7223, accuracy: 0.5000, val_loss: 0.7044, val_accuracy: 0.5375
2024-12-20 16:18:14,581 [INFO]: Epoch 1000/1000: loss: 0.7120, accuracy: 0.5000, val_loss: 0.6977, val_accuracy: 0.5375
2024-12-20 16:18:15,645 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=MBGD, Layers=1...
2024-12-20 16:18:15,959 [INFO]: Epoch 1/1000: loss: 0.7459, accuracy: 0.5000, val_loss: 0.7688, val_accuracy: 0.4625
2024-12-20 16:18:55,494 [INFO]: Epoch 1000/1000: loss: 0.6760, accuracy: 0.6708, val_loss: 0.6777, val_accuracy: 0.6750
2024-12-20 16:18:56,535 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=MBGD, Layers=2...
2024-12-20 16:18:56,871 [INFO]: Epoch 1/1000: loss: 0.7079, accuracy: 0.2167, val_loss: 0.7076, val_accuracy: 0.2000
2024-12-20 16:19:36,461 [INFO]: Epoch 1000/1000: loss: 0.7051, accuracy: 0.2042, val_loss: 0.7051, val_accuracy: 0.2125
2024-12-20 16:19:37,506 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=MBGD, Layers=3...
2024-12-20 16:19:37,869 [INFO]: Epoch 1/1000: loss: 0.7792, accuracy: 0.5000, val_loss: 0.8105, val_accuracy: 0.4625
2024-12-20 16:20:17,583 [INFO]: Epoch 1000/1000: loss: 0.6942, accuracy: 0.5000, val_loss: 0.6977, val_accuracy: 0.4625
2024-12-20 16:20:18,875 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=SGD, Layers=1...
2024-12-20 16:20:19,294 [INFO]: Epoch 1/50: loss: 0.8178, accuracy: 0.5000, val_loss: 0.7345, val_accuracy: 0.5375
2024-12-20 16:20:27,466 [INFO]: Epoch 50/50: loss: 0.5110, accuracy: 0.8292, val_loss: 0.5046, val_accuracy: 0.8375
2024-12-20 16:20:28,521 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=SGD, Layers=2...
2024-12-20 16:20:28,966 [INFO]: Epoch 1/50: loss: 0.6911, accuracy: 0.5000, val_loss: 0.6841, val_accuracy: 0.5375
2024-12-20 16:20:37,273 [INFO]: Epoch 50/50: loss: 0.6524, accuracy: 0.7875, val_loss: 0.6489, val_accuracy: 0.8250
2024-12-20 16:20:38,351 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=SGD, Layers=3...
2024-12-20 16:20:38,805 [INFO]: Epoch 1/50: loss: 0.7126, accuracy: 0.5000, val_loss: 0.6917, val_accuracy: 0.5375
2024-12-20 16:20:47,201 [INFO]: Epoch 50/50: loss: 0.6914, accuracy: 0.5458, val_loss: 0.6892, val_accuracy: 0.5375
2024-12-20 16:20:48,279 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=BGD, Layers=1...
2024-12-20 16:20:48,552 [INFO]: Epoch 1/50: loss: 0.7075, accuracy: 0.2167, val_loss: 0.7087, val_accuracy: 0.2250
2024-12-20 16:20:50,230 [INFO]: Epoch 50/50: loss: 0.7062, accuracy: 0.2083, val_loss: 0.7072, val_accuracy: 0.2250
2024-12-20 16:20:51,277 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=BGD, Layers=2...
2024-12-20 16:20:51,569 [INFO]: Epoch 1/50: loss: 0.8648, accuracy: 0.5000, val_loss: 0.8188, val_accuracy: 0.5375
2024-12-20 16:20:53,230 [INFO]: Epoch 50/50: loss: 0.8321, accuracy: 0.5000, val_loss: 0.7910, val_accuracy: 0.5375
2024-12-20 16:20:54,297 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=BGD, Layers=3...
2024-12-20 16:20:54,614 [INFO]: Epoch 1/50: loss: 0.7162, accuracy: 0.5000, val_loss: 0.7000, val_accuracy: 0.5375
2024-12-20 16:20:56,276 [INFO]: Epoch 50/50: loss: 0.7107, accuracy: 0.5000, val_loss: 0.6965, val_accuracy: 0.5375
2024-12-20 16:20:57,351 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=MBGD, Layers=1...
2024-12-20 16:20:57,662 [INFO]: Epoch 1/50: loss: 0.6263, accuracy: 0.7875, val_loss: 0.6199, val_accuracy: 0.7875
2024-12-20 16:20:59,603 [INFO]: Epoch 50/50: loss: 0.6170, accuracy: 0.8542, val_loss: 0.6133, val_accuracy: 0.8375
2024-12-20 16:21:00,649 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=MBGD, Layers=2...
2024-12-20 16:21:00,985 [INFO]: Epoch 1/50: loss: 0.7496, accuracy: 0.5000, val_loss: 0.7737, val_accuracy: 0.4625
2024-12-20 16:21:02,930 [INFO]: Epoch 50/50: loss: 0.6967, accuracy: 0.5000, val_loss: 0.7049, val_accuracy: 0.4625
2024-12-20 16:21:03,991 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=MBGD, Layers=3...
2024-12-20 16:21:04,346 [INFO]: Epoch 1/50: loss: 0.6958, accuracy: 0.5000, val_loss: 0.6913, val_accuracy: 0.5375
2024-12-20 16:21:06,305 [INFO]: Epoch 50/50: loss: 0.6942, accuracy: 0.5000, val_loss: 0.6925, val_accuracy: 0.5375
2024-12-20 16:21:07,596 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=SGD, Layers=1...
2024-12-20 16:21:08,020 [INFO]: Epoch 1/250: loss: 0.7510, accuracy: 0.5000, val_loss: 0.7093, val_accuracy: 0.5375
2024-12-20 16:21:49,425 [INFO]: Epoch 250/250: loss: 0.3032, accuracy: 0.8458, val_loss: 0.3290, val_accuracy: 0.8375
2024-12-20 16:21:50,485 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=SGD, Layers=2...
2024-12-20 16:21:50,921 [INFO]: Epoch 1/250: loss: 0.7090, accuracy: 0.5000, val_loss: 0.7103, val_accuracy: 0.4625
2024-12-20 16:22:33,031 [INFO]: Epoch 250/250: loss: 0.3510, accuracy: 0.8333, val_loss: 0.3582, val_accuracy: 0.8250
2024-12-20 16:22:34,127 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=SGD, Layers=3...
2024-12-20 16:22:34,588 [INFO]: Epoch 1/250: loss: 0.7224, accuracy: 0.5000, val_loss: 0.6936, val_accuracy: 0.5375
2024-12-20 16:23:17,225 [INFO]: Epoch 250/250: loss: 0.6572, accuracy: 0.7917, val_loss: 0.6548, val_accuracy: 0.7875
2024-12-20 16:23:18,302 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=BGD, Layers=1...
2024-12-20 16:23:18,575 [INFO]: Epoch 1/250: loss: 0.7166, accuracy: 0.5000, val_loss: 0.7371, val_accuracy: 0.4625
2024-12-20 16:23:27,049 [INFO]: Epoch 250/250: loss: 0.6695, accuracy: 0.5000, val_loss: 0.6802, val_accuracy: 0.4625
2024-12-20 16:23:28,103 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=BGD, Layers=2...
2024-12-20 16:23:28,398 [INFO]: Epoch 1/250: loss: 0.8718, accuracy: 0.5000, val_loss: 0.9166, val_accuracy: 0.4625
2024-12-20 16:23:36,861 [INFO]: Epoch 250/250: loss: 0.7551, accuracy: 0.5000, val_loss: 0.7797, val_accuracy: 0.4625
2024-12-20 16:23:37,914 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=BGD, Layers=3...
2024-12-20 16:23:38,241 [INFO]: Epoch 1/250: loss: 0.8613, accuracy: 0.5000, val_loss: 0.9050, val_accuracy: 0.4625
2024-12-20 16:23:46,662 [INFO]: Epoch 250/250: loss: 0.7448, accuracy: 0.5000, val_loss: 0.7683, val_accuracy: 0.4625
2024-12-20 16:23:47,731 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=MBGD, Layers=1...
2024-12-20 16:23:48,042 [INFO]: Epoch 1/250: loss: 0.9463, accuracy: 0.5000, val_loss: 0.8878, val_accuracy: 0.5375
2024-12-20 16:23:57,895 [INFO]: Epoch 250/250: loss: 0.6868, accuracy: 0.6625, val_loss: 0.6862, val_accuracy: 0.6500
2024-12-20 16:23:58,941 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=MBGD, Layers=2...
2024-12-20 16:23:59,271 [INFO]: Epoch 1/250: loss: 0.6907, accuracy: 0.5000, val_loss: 0.6931, val_accuracy: 0.4625
2024-12-20 16:24:09,147 [INFO]: Epoch 250/250: loss: 0.6870, accuracy: 0.6625, val_loss: 0.6867, val_accuracy: 0.6625
2024-12-20 16:24:10,216 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=MBGD, Layers=3...
2024-12-20 16:24:10,578 [INFO]: Epoch 1/250: loss: 0.7207, accuracy: 0.5000, val_loss: 0.7379, val_accuracy: 0.4625
2024-12-20 16:24:20,487 [INFO]: Epoch 250/250: loss: 0.6909, accuracy: 0.8167, val_loss: 0.6909, val_accuracy: 0.8000
2024-12-20 16:24:21,560 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=SGD, Layers=1...
2024-12-20 16:24:22,224 [INFO]: Epoch 1/500: loss: 0.6838, accuracy: 0.5458, val_loss: 0.6755, val_accuracy: 0.6250
2024-12-20 16:25:45,478 [INFO]: Epoch 500/500: loss: 0.2751, accuracy: 0.8583, val_loss: 0.3277, val_accuracy: 0.8375
2024-12-20 16:25:46,541 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=SGD, Layers=2...
2024-12-20 16:25:46,990 [INFO]: Epoch 1/500: loss: 0.6959, accuracy: 0.5000, val_loss: 0.6977, val_accuracy: 0.4625
2024-12-20 16:27:11,411 [INFO]: Epoch 500/500: loss: 0.2780, accuracy: 0.8500, val_loss: 0.3289, val_accuracy: 0.8375
2024-12-20 16:27:12,494 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=SGD, Layers=3...
2024-12-20 16:27:12,958 [INFO]: Epoch 1/500: loss: 0.6997, accuracy: 0.5000, val_loss: 0.6909, val_accuracy: 0.5375
2024-12-20 16:28:38,363 [INFO]: Epoch 500/500: loss: 0.3778, accuracy: 0.8125, val_loss: 0.3782, val_accuracy: 0.8125
2024-12-20 16:28:39,467 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=BGD, Layers=1...
2024-12-20 16:28:39,741 [INFO]: Epoch 1/500: loss: 0.7101, accuracy: 0.5000, val_loss: 0.7237, val_accuracy: 0.4625
2024-12-20 16:28:56,741 [INFO]: Epoch 500/500: loss: 0.6847, accuracy: 0.5000, val_loss: 0.6886, val_accuracy: 0.4625
2024-12-20 16:28:57,804 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=BGD, Layers=2...
2024-12-20 16:28:58,096 [INFO]: Epoch 1/500: loss: 0.7081, accuracy: 0.5000, val_loss: 0.6921, val_accuracy: 0.5375
2024-12-20 16:29:15,062 [INFO]: Epoch 500/500: loss: 0.6867, accuracy: 0.5000, val_loss: 0.6824, val_accuracy: 0.5375
2024-12-20 16:29:16,112 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=BGD, Layers=3...
2024-12-20 16:29:16,432 [INFO]: Epoch 1/500: loss: 0.7991, accuracy: 0.5000, val_loss: 0.7638, val_accuracy: 0.5375
2024-12-20 16:29:33,331 [INFO]: Epoch 500/500: loss: 0.7064, accuracy: 0.5000, val_loss: 0.6952, val_accuracy: 0.5375
2024-12-20 16:29:34,415 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=MBGD, Layers=1...
2024-12-20 16:29:34,732 [INFO]: Epoch 1/500: loss: 0.7049, accuracy: 0.5000, val_loss: 0.6948, val_accuracy: 0.5375
2024-12-20 16:29:54,473 [INFO]: Epoch 500/500: loss: 0.6293, accuracy: 0.7458, val_loss: 0.6263, val_accuracy: 0.7625
2024-12-20 16:29:55,520 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=MBGD, Layers=2...
2024-12-20 16:29:55,858 [INFO]: Epoch 1/500: loss: 0.7962, accuracy: 0.5000, val_loss: 0.8287, val_accuracy: 0.4625
2024-12-20 16:30:15,682 [INFO]: Epoch 500/500: loss: 0.6679, accuracy: 0.7917, val_loss: 0.6668, val_accuracy: 0.8125
2024-12-20 16:30:16,757 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=MBGD, Layers=3...
2024-12-20 16:30:17,114 [INFO]: Epoch 1/500: loss: 0.7540, accuracy: 0.5000, val_loss: 0.7785, val_accuracy: 0.4625
2024-12-20 16:30:36,963 [INFO]: Epoch 500/500: loss: 0.6908, accuracy: 0.7000, val_loss: 0.6906, val_accuracy: 0.7250
2024-12-20 16:30:38,046 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=SGD, Layers=1...
2024-12-20 16:30:38,448 [INFO]: Epoch 1/1000: loss: 0.7420, accuracy: 0.5000, val_loss: 0.7208, val_accuracy: 0.4625
2024-12-20 16:33:22,717 [INFO]: Epoch 1000/1000: loss: 0.2721, accuracy: 0.8583, val_loss: 0.3366, val_accuracy: 0.8250
2024-12-20 16:33:23,752 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=SGD, Layers=2...
2024-12-20 16:33:24,180 [INFO]: Epoch 1/1000: loss: 0.6876, accuracy: 0.5875, val_loss: 0.6832, val_accuracy: 0.5500
2024-12-20 16:36:10,949 [INFO]: Epoch 1000/1000: loss: 0.2745, accuracy: 0.8542, val_loss: 0.3394, val_accuracy: 0.8250
2024-12-20 16:36:12,273 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=SGD, Layers=3...
2024-12-20 16:36:12,758 [INFO]: Epoch 1/1000: loss: 1.0979, accuracy: 0.5000, val_loss: 1.0037, val_accuracy: 0.4625
2024-12-20 16:39:04,256 [INFO]: Epoch 1000/1000: loss: 0.2776, accuracy: 0.8583, val_loss: 0.3379, val_accuracy: 0.8250
2024-12-20 16:39:05,348 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=BGD, Layers=1...
2024-12-20 16:39:05,629 [INFO]: Epoch 1/1000: loss: 0.7096, accuracy: 0.4292, val_loss: 0.7124, val_accuracy: 0.4000
2024-12-20 16:39:39,993 [INFO]: Epoch 1000/1000: loss: 0.6911, accuracy: 0.5000, val_loss: 0.6925, val_accuracy: 0.4625
2024-12-20 16:39:41,040 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=BGD, Layers=2...
2024-12-20 16:39:41,340 [INFO]: Epoch 1/1000: loss: 0.7631, accuracy: 0.5000, val_loss: 0.7910, val_accuracy: 0.4625
2024-12-20 16:40:15,518 [INFO]: Epoch 1000/1000: loss: 0.6939, accuracy: 0.5000, val_loss: 0.6954, val_accuracy: 0.4625
2024-12-20 16:40:16,595 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=BGD, Layers=3...
2024-12-20 16:40:16,918 [INFO]: Epoch 1/1000: loss: 0.6923, accuracy: 0.5000, val_loss: 0.6916, val_accuracy: 0.5375
2024-12-20 16:40:51,036 [INFO]: Epoch 1000/1000: loss: 0.6922, accuracy: 0.5333, val_loss: 0.6921, val_accuracy: 0.5125
2024-12-20 16:40:52,111 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=MBGD, Layers=1...
2024-12-20 16:40:52,422 [INFO]: Epoch 1/1000: loss: 0.7017, accuracy: 0.4917, val_loss: 0.7177, val_accuracy: 0.4625
2024-12-20 16:41:32,119 [INFO]: Epoch 1000/1000: loss: 0.5004, accuracy: 0.8417, val_loss: 0.4991, val_accuracy: 0.8250
2024-12-20 16:41:33,182 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=MBGD, Layers=2...
2024-12-20 16:41:33,519 [INFO]: Epoch 1/1000: loss: 0.7498, accuracy: 0.5000, val_loss: 0.7734, val_accuracy: 0.4625
2024-12-20 16:42:13,276 [INFO]: Epoch 1000/1000: loss: 0.6770, accuracy: 0.8250, val_loss: 0.6763, val_accuracy: 0.8375
2024-12-20 16:42:14,331 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=MBGD, Layers=3...
2024-12-20 16:42:14,687 [INFO]: Epoch 1/1000: loss: 0.7093, accuracy: 0.5000, val_loss: 0.6952, val_accuracy: 0.5375
2024-12-20 16:42:54,463 [INFO]: Epoch 1000/1000: loss: 0.6914, accuracy: 0.7625, val_loss: 0.6914, val_accuracy: 0.8125
2024-12-20 16:42:55,550 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=SGD, Layers=1...
2024-12-20 16:42:55,954 [INFO]: Epoch 1/50: loss: 0.6999, accuracy: 0.5875, val_loss: 0.6506, val_accuracy: 0.7500
2024-12-20 16:43:04,016 [INFO]: Epoch 50/50: loss: 0.2781, accuracy: 0.8583, val_loss: 0.3315, val_accuracy: 0.8500
2024-12-20 16:43:05,061 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=SGD, Layers=2...
2024-12-20 16:43:05,497 [INFO]: Epoch 1/50: loss: 0.7112, accuracy: 0.4792, val_loss: 0.6848, val_accuracy: 0.5375
2024-12-20 16:43:13,655 [INFO]: Epoch 50/50: loss: 0.2838, accuracy: 0.8667, val_loss: 0.3329, val_accuracy: 0.8125
2024-12-20 16:43:14,717 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=SGD, Layers=3...
2024-12-20 16:43:15,168 [INFO]: Epoch 1/50: loss: 0.7017, accuracy: 0.5292, val_loss: 0.6907, val_accuracy: 0.5375
2024-12-20 16:43:23,414 [INFO]: Epoch 50/50: loss: 0.4946, accuracy: 0.7708, val_loss: 0.4712, val_accuracy: 0.8125
2024-12-20 16:43:24,489 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=BGD, Layers=1...
2024-12-20 16:43:25,060 [INFO]: Epoch 1/50: loss: 0.7985, accuracy: 0.5000, val_loss: 0.7655, val_accuracy: 0.5375
2024-12-20 16:43:26,881 [INFO]: Epoch 50/50: loss: 0.7253, accuracy: 0.5000, val_loss: 0.7147, val_accuracy: 0.5375
2024-12-20 16:43:27,924 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=BGD, Layers=2...
2024-12-20 16:43:28,243 [INFO]: Epoch 1/50: loss: 0.7503, accuracy: 0.5000, val_loss: 0.7215, val_accuracy: 0.5375
2024-12-20 16:43:29,963 [INFO]: Epoch 50/50: loss: 0.6928, accuracy: 0.5000, val_loss: 0.6849, val_accuracy: 0.5375
2024-12-20 16:43:31,049 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=BGD, Layers=3...
2024-12-20 16:43:31,377 [INFO]: Epoch 1/50: loss: 1.0692, accuracy: 0.5000, val_loss: 1.1214, val_accuracy: 0.4625
2024-12-20 16:43:33,071 [INFO]: Epoch 50/50: loss: 0.7234, accuracy: 0.5000, val_loss: 0.7401, val_accuracy: 0.4625
2024-12-20 16:43:34,138 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=MBGD, Layers=1...
2024-12-20 16:43:34,456 [INFO]: Epoch 1/50: loss: 0.6977, accuracy: 0.5000, val_loss: 0.7032, val_accuracy: 0.4625
2024-12-20 16:43:36,443 [INFO]: Epoch 50/50: loss: 0.6080, accuracy: 0.8208, val_loss: 0.6049, val_accuracy: 0.8125
2024-12-20 16:43:37,500 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=MBGD, Layers=2...
2024-12-20 16:43:37,843 [INFO]: Epoch 1/50: loss: 0.7278, accuracy: 0.5000, val_loss: 0.7374, val_accuracy: 0.4625
2024-12-20 16:43:39,811 [INFO]: Epoch 50/50: loss: 0.6862, accuracy: 0.5875, val_loss: 0.6860, val_accuracy: 0.7250
2024-12-20 16:43:40,881 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=MBGD, Layers=3...
2024-12-20 16:43:41,238 [INFO]: Epoch 1/50: loss: 0.6961, accuracy: 0.5000, val_loss: 0.6908, val_accuracy: 0.5375
2024-12-20 16:43:43,215 [INFO]: Epoch 50/50: loss: 0.6929, accuracy: 0.5125, val_loss: 0.6932, val_accuracy: 0.4625
2024-12-20 16:43:44,283 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=SGD, Layers=1...
2024-12-20 16:43:44,691 [INFO]: Epoch 1/250: loss: 0.6564, accuracy: 0.6250, val_loss: 0.6259, val_accuracy: 0.8125
2024-12-20 16:44:25,774 [INFO]: Epoch 250/250: loss: 0.2751, accuracy: 0.8583, val_loss: 0.3359, val_accuracy: 0.8250
2024-12-20 16:44:26,822 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=SGD, Layers=2...
2024-12-20 16:44:27,250 [INFO]: Epoch 1/250: loss: 0.7048, accuracy: 0.5167, val_loss: 0.6877, val_accuracy: 0.5375
2024-12-20 16:45:08,860 [INFO]: Epoch 250/250: loss: 0.2778, accuracy: 0.8583, val_loss: 0.3380, val_accuracy: 0.8250
2024-12-20 16:45:09,905 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=SGD, Layers=3...
2024-12-20 16:45:10,368 [INFO]: Epoch 1/250: loss: 0.7059, accuracy: 0.4583, val_loss: 0.7007, val_accuracy: 0.4625
2024-12-20 16:45:52,607 [INFO]: Epoch 250/250: loss: 0.2837, accuracy: 0.8542, val_loss: 0.3410, val_accuracy: 0.8250
2024-12-20 16:45:53,670 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=BGD, Layers=1...
2024-12-20 16:45:53,941 [INFO]: Epoch 1/250: loss: 0.7673, accuracy: 0.4250, val_loss: 0.7572, val_accuracy: 0.4250
2024-12-20 16:46:02,367 [INFO]: Epoch 250/250: loss: 0.7072, accuracy: 0.3792, val_loss: 0.7076, val_accuracy: 0.3750
2024-12-20 16:46:03,426 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=BGD, Layers=2...
2024-12-20 16:46:03,714 [INFO]: Epoch 1/250: loss: 0.6931, accuracy: 0.5000, val_loss: 0.6869, val_accuracy: 0.5375
2024-12-20 16:46:12,140 [INFO]: Epoch 250/250: loss: 0.6851, accuracy: 0.7792, val_loss: 0.6849, val_accuracy: 0.7875
2024-12-20 16:46:13,213 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=BGD, Layers=3...
2024-12-20 16:46:13,533 [INFO]: Epoch 1/250: loss: 0.9541, accuracy: 0.5000, val_loss: 0.9984, val_accuracy: 0.4625
2024-12-20 16:46:21,967 [INFO]: Epoch 250/250: loss: 0.6931, accuracy: 0.6292, val_loss: 0.6931, val_accuracy: 0.6125
2024-12-20 16:46:23,378 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=MBGD, Layers=1...
2024-12-20 16:46:23,722 [INFO]: Epoch 1/250: loss: 0.7043, accuracy: 0.5000, val_loss: 0.7106, val_accuracy: 0.4625
2024-12-20 16:46:33,957 [INFO]: Epoch 250/250: loss: 0.4255, accuracy: 0.8167, val_loss: 0.4234, val_accuracy: 0.8125
2024-12-20 16:46:35,014 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=MBGD, Layers=2...
2024-12-20 16:46:35,360 [INFO]: Epoch 1/250: loss: 0.6972, accuracy: 0.5000, val_loss: 0.6885, val_accuracy: 0.5375
2024-12-20 16:46:45,453 [INFO]: Epoch 250/250: loss: 0.6288, accuracy: 0.8000, val_loss: 0.6267, val_accuracy: 0.8125
2024-12-20 16:46:46,536 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=MBGD, Layers=3...
2024-12-20 16:46:46,898 [INFO]: Epoch 1/250: loss: 0.7127, accuracy: 0.5000, val_loss: 0.7211, val_accuracy: 0.4625
2024-12-20 16:46:56,971 [INFO]: Epoch 250/250: loss: 0.6916, accuracy: 0.7167, val_loss: 0.6907, val_accuracy: 0.6125
2024-12-20 16:46:58,071 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=SGD, Layers=1...
2024-12-20 16:46:58,483 [INFO]: Epoch 1/500: loss: 0.7192, accuracy: 0.4417, val_loss: 0.6680, val_accuracy: 0.6750
2024-12-20 16:48:21,223 [INFO]: Epoch 500/500: loss: 0.1932, accuracy: 0.9167, val_loss: 0.2493, val_accuracy: 0.8875
2024-12-20 16:48:22,274 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=SGD, Layers=2...
2024-12-20 16:48:22,705 [INFO]: Epoch 1/500: loss: 0.7027, accuracy: 0.5125, val_loss: 0.6912, val_accuracy: 0.4625
2024-12-20 16:49:46,825 [INFO]: Epoch 500/500: loss: 0.0941, accuracy: 0.9625, val_loss: 0.1201, val_accuracy: 0.9625
2024-12-20 16:49:47,887 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=SGD, Layers=3...
2024-12-20 16:49:48,346 [INFO]: Epoch 1/500: loss: 0.7086, accuracy: 0.5292, val_loss: 0.6916, val_accuracy: 0.5375
2024-12-20 16:51:13,199 [INFO]: Epoch 500/500: loss: 0.2753, accuracy: 0.8708, val_loss: 0.3544, val_accuracy: 0.8125
2024-12-20 16:51:14,292 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=BGD, Layers=1...
2024-12-20 16:51:14,565 [INFO]: Epoch 1/500: loss: 0.7004, accuracy: 0.5000, val_loss: 0.6908, val_accuracy: 0.5375
2024-12-20 16:51:31,439 [INFO]: Epoch 500/500: loss: 0.5951, accuracy: 0.7542, val_loss: 0.5915, val_accuracy: 0.7875
2024-12-20 16:51:32,498 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=BGD, Layers=2...
2024-12-20 16:51:32,787 [INFO]: Epoch 1/500: loss: 0.6889, accuracy: 0.5000, val_loss: 0.6828, val_accuracy: 0.5375
2024-12-20 16:51:49,658 [INFO]: Epoch 500/500: loss: 0.6741, accuracy: 0.8208, val_loss: 0.6734, val_accuracy: 0.8125
2024-12-20 16:51:50,727 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=BGD, Layers=3...
2024-12-20 16:51:51,046 [INFO]: Epoch 1/500: loss: 0.8646, accuracy: 0.5000, val_loss: 0.8131, val_accuracy: 0.5375
2024-12-20 16:52:07,936 [INFO]: Epoch 500/500: loss: 0.6923, accuracy: 0.5583, val_loss: 0.6923, val_accuracy: 0.5375
2024-12-20 16:52:09,014 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=MBGD, Layers=1...
2024-12-20 16:52:09,322 [INFO]: Epoch 1/500: loss: 0.8533, accuracy: 0.5000, val_loss: 0.8697, val_accuracy: 0.4625
2024-12-20 16:52:29,062 [INFO]: Epoch 500/500: loss: 0.3299, accuracy: 0.8417, val_loss: 0.3438, val_accuracy: 0.8250
2024-12-20 16:52:30,114 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=MBGD, Layers=2...
2024-12-20 16:52:30,449 [INFO]: Epoch 1/500: loss: 0.9448, accuracy: 0.5000, val_loss: 0.8472, val_accuracy: 0.5375
2024-12-20 16:52:50,262 [INFO]: Epoch 500/500: loss: 0.4744, accuracy: 0.8083, val_loss: 0.4701, val_accuracy: 0.8125
2024-12-20 16:52:51,323 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=MBGD, Layers=3...
2024-12-20 16:52:51,680 [INFO]: Epoch 1/500: loss: 0.7602, accuracy: 0.5000, val_loss: 0.7731, val_accuracy: 0.4625
2024-12-20 16:53:11,539 [INFO]: Epoch 500/500: loss: 0.6819, accuracy: 0.7500, val_loss: 0.6807, val_accuracy: 0.7625
2024-12-20 16:53:12,963 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=SGD, Layers=1...
2024-12-20 16:53:13,393 [INFO]: Epoch 1/1000: loss: 0.7085, accuracy: 0.5000, val_loss: 0.6598, val_accuracy: 0.8000
2024-12-20 16:56:00,510 [INFO]: Epoch 1000/1000: loss: 0.0874, accuracy: 0.9625, val_loss: 0.1167, val_accuracy: 0.9750
2024-12-20 16:56:01,573 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=SGD, Layers=2...
2024-12-20 16:56:02,018 [INFO]: Epoch 1/1000: loss: 0.7292, accuracy: 0.4792, val_loss: 0.6870, val_accuracy: 0.5375
2024-12-20 16:58:51,202 [INFO]: Epoch 1000/1000: loss: 0.0800, accuracy: 0.9708, val_loss: 0.1044, val_accuracy: 0.9625
2024-12-20 16:58:52,272 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=SGD, Layers=3...
2024-12-20 16:58:52,746 [INFO]: Epoch 1/1000: loss: 0.7468, accuracy: 0.4750, val_loss: 0.6941, val_accuracy: 0.5375
2024-12-20 17:01:44,062 [INFO]: Epoch 1000/1000: loss: 0.0805, accuracy: 0.9667, val_loss: 0.0990, val_accuracy: 0.9625
2024-12-20 17:01:45,162 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=BGD, Layers=1...
2024-12-20 17:01:45,437 [INFO]: Epoch 1/1000: loss: 0.6983, accuracy: 0.5000, val_loss: 0.6856, val_accuracy: 0.5375
2024-12-20 17:02:19,621 [INFO]: Epoch 1000/1000: loss: 0.5004, accuracy: 0.7958, val_loss: 0.4956, val_accuracy: 0.8000
2024-12-20 17:02:20,676 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=BGD, Layers=2...
2024-12-20 17:02:20,973 [INFO]: Epoch 1/1000: loss: 0.8322, accuracy: 0.5000, val_loss: 0.7851, val_accuracy: 0.5375
2024-12-20 17:02:55,129 [INFO]: Epoch 1000/1000: loss: 0.6593, accuracy: 0.7958, val_loss: 0.6583, val_accuracy: 0.8000
2024-12-20 17:02:56,199 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=BGD, Layers=3...
2024-12-20 17:02:56,520 [INFO]: Epoch 1/1000: loss: 0.8187, accuracy: 0.5000, val_loss: 0.7760, val_accuracy: 0.5375
2024-12-20 17:03:30,520 [INFO]: Epoch 1000/1000: loss: 0.6931, accuracy: 0.5000, val_loss: 0.6930, val_accuracy: 0.5375
2024-12-20 17:03:31,597 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=MBGD, Layers=1...
2024-12-20 17:03:31,914 [INFO]: Epoch 1/1000: loss: 0.9024, accuracy: 0.5000, val_loss: 0.9169, val_accuracy: 0.4625
2024-12-20 17:04:11,565 [INFO]: Epoch 1000/1000: loss: 0.2880, accuracy: 0.8500, val_loss: 0.3247, val_accuracy: 0.8500
2024-12-20 17:04:12,607 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=MBGD, Layers=2...
2024-12-20 17:04:12,945 [INFO]: Epoch 1/1000: loss: 0.7838, accuracy: 0.5000, val_loss: 0.7941, val_accuracy: 0.4625
2024-12-20 17:04:52,716 [INFO]: Epoch 1000/1000: loss: 0.3073, accuracy: 0.8458, val_loss: 0.3328, val_accuracy: 0.8250
2024-12-20 17:04:53,785 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=MBGD, Layers=3...
2024-12-20 17:04:54,141 [INFO]: Epoch 1/1000: loss: 0.7002, accuracy: 0.5000, val_loss: 0.7060, val_accuracy: 0.4625
2024-12-20 17:05:33,911 [INFO]: Epoch 1000/1000: loss: 0.6365, accuracy: 0.7708, val_loss: 0.6345, val_accuracy: 0.7875
2024-12-20 17:05:35,010 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=SGD, Layers=1...
2024-12-20 17:05:35,418 [INFO]: Epoch 1/50: loss: 0.5643, accuracy: 0.7125, val_loss: 0.4154, val_accuracy: 0.7875
2024-12-20 17:05:43,507 [INFO]: Epoch 50/50: loss: 0.2562, accuracy: 0.8708, val_loss: 0.3025, val_accuracy: 0.8250
2024-12-20 17:05:44,556 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=SGD, Layers=2...
2024-12-20 17:05:44,984 [INFO]: Epoch 1/50: loss: 0.6940, accuracy: 0.6042, val_loss: 0.6826, val_accuracy: 0.4625
2024-12-20 17:05:53,178 [INFO]: Epoch 50/50: loss: 0.2797, accuracy: 0.8583, val_loss: 0.3257, val_accuracy: 0.8250
2024-12-20 17:05:54,259 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=SGD, Layers=3...
2024-12-20 17:05:54,712 [INFO]: Epoch 1/50: loss: 0.7662, accuracy: 0.5000, val_loss: 0.6904, val_accuracy: 0.5375
2024-12-20 17:06:03,026 [INFO]: Epoch 50/50: loss: 0.2803, accuracy: 0.8583, val_loss: 0.3378, val_accuracy: 0.8125
2024-12-20 17:06:04,465 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=BGD, Layers=1...
2024-12-20 17:06:04,764 [INFO]: Epoch 1/50: loss: 0.6791, accuracy: 0.5000, val_loss: 0.6629, val_accuracy: 0.5375
2024-12-20 17:06:06,539 [INFO]: Epoch 50/50: loss: 0.5812, accuracy: 0.8250, val_loss: 0.5776, val_accuracy: 0.8125
2024-12-20 17:06:07,594 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=BGD, Layers=2...
2024-12-20 17:06:07,908 [INFO]: Epoch 1/50: loss: 0.6969, accuracy: 0.5000, val_loss: 0.6992, val_accuracy: 0.4625
2024-12-20 17:06:09,628 [INFO]: Epoch 50/50: loss: 0.6853, accuracy: 0.8208, val_loss: 0.6850, val_accuracy: 0.7625
2024-12-20 17:06:10,723 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=BGD, Layers=3...
2024-12-20 17:06:11,050 [INFO]: Epoch 1/50: loss: 0.7590, accuracy: 0.5000, val_loss: 0.7502, val_accuracy: 0.4625
2024-12-20 17:06:12,739 [INFO]: Epoch 50/50: loss: 0.6923, accuracy: 0.8000, val_loss: 0.6923, val_accuracy: 0.8375
2024-12-20 17:06:13,837 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=MBGD, Layers=1...
2024-12-20 17:06:14,152 [INFO]: Epoch 1/50: loss: 0.6475, accuracy: 0.7000, val_loss: 0.6308, val_accuracy: 0.7750
2024-12-20 17:06:16,120 [INFO]: Epoch 50/50: loss: 0.3283, accuracy: 0.8417, val_loss: 0.3419, val_accuracy: 0.8250
2024-12-20 17:06:17,174 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=MBGD, Layers=2...
2024-12-20 17:06:17,517 [INFO]: Epoch 1/50: loss: 0.7330, accuracy: 0.5000, val_loss: 0.7036, val_accuracy: 0.2375
2024-12-20 17:06:19,487 [INFO]: Epoch 50/50: loss: 0.5859, accuracy: 0.7833, val_loss: 0.5861, val_accuracy: 0.7625
2024-12-20 17:06:20,584 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=MBGD, Layers=3...
2024-12-20 17:06:20,941 [INFO]: Epoch 1/50: loss: 0.6975, accuracy: 0.5000, val_loss: 0.6904, val_accuracy: 0.5375
2024-12-20 17:06:22,907 [INFO]: Epoch 50/50: loss: 0.6827, accuracy: 0.6917, val_loss: 0.6821, val_accuracy: 0.6000
2024-12-20 17:06:23,982 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=SGD, Layers=1...
2024-12-20 17:06:24,385 [INFO]: Epoch 1/250: loss: 0.5427, accuracy: 0.6875, val_loss: 0.3813, val_accuracy: 0.8375
2024-12-20 17:07:05,596 [INFO]: Epoch 250/250: loss: 0.0787, accuracy: 0.9667, val_loss: 0.1124, val_accuracy: 0.9625
2024-12-20 17:07:06,631 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=SGD, Layers=2...
2024-12-20 17:07:07,073 [INFO]: Epoch 1/250: loss: 0.7163, accuracy: 0.5625, val_loss: 0.7027, val_accuracy: 0.5375
2024-12-20 17:07:48,945 [INFO]: Epoch 250/250: loss: 0.2606, accuracy: 0.8625, val_loss: 0.2963, val_accuracy: 0.8750
2024-12-20 17:07:50,019 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=SGD, Layers=3...
2024-12-20 17:07:50,468 [INFO]: Epoch 1/250: loss: 0.7712, accuracy: 0.4833, val_loss: 0.6901, val_accuracy: 0.5375
2024-12-20 17:08:32,653 [INFO]: Epoch 250/250: loss: 0.0805, accuracy: 0.9750, val_loss: 0.1049, val_accuracy: 0.9625
2024-12-20 17:08:33,738 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=BGD, Layers=1...
2024-12-20 17:08:34,010 [INFO]: Epoch 1/250: loss: 0.7093, accuracy: 0.5000, val_loss: 0.6941, val_accuracy: 0.5375
2024-12-20 17:08:42,425 [INFO]: Epoch 250/250: loss: 0.3941, accuracy: 0.8125, val_loss: 0.3935, val_accuracy: 0.8125
2024-12-20 17:08:43,463 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=BGD, Layers=2...
2024-12-20 17:08:43,755 [INFO]: Epoch 1/250: loss: 0.6973, accuracy: 0.5000, val_loss: 0.7010, val_accuracy: 0.4625
2024-12-20 17:08:52,173 [INFO]: Epoch 250/250: loss: 0.6043, accuracy: 0.8083, val_loss: 0.6016, val_accuracy: 0.8125
2024-12-20 17:08:53,256 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=BGD, Layers=3...
2024-12-20 17:08:53,573 [INFO]: Epoch 1/250: loss: 0.7064, accuracy: 0.5000, val_loss: 0.7093, val_accuracy: 0.4625
2024-12-20 17:09:01,986 [INFO]: Epoch 250/250: loss: 0.6887, accuracy: 0.8208, val_loss: 0.6886, val_accuracy: 0.8125
2024-12-20 17:09:03,062 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=MBGD, Layers=1...
2024-12-20 17:09:03,373 [INFO]: Epoch 1/250: loss: 0.7702, accuracy: 0.5000, val_loss: 0.7040, val_accuracy: 0.4625
2024-12-20 17:09:13,234 [INFO]: Epoch 250/250: loss: 0.2734, accuracy: 0.8458, val_loss: 0.3357, val_accuracy: 0.8250
2024-12-20 17:09:14,285 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=MBGD, Layers=2...
2024-12-20 17:09:14,617 [INFO]: Epoch 1/250: loss: 0.7168, accuracy: 0.5000, val_loss: 0.6967, val_accuracy: 0.4625
2024-12-20 17:09:24,499 [INFO]: Epoch 250/250: loss: 0.2748, accuracy: 0.8583, val_loss: 0.3384, val_accuracy: 0.8250
2024-12-20 17:09:25,942 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=MBGD, Layers=3...
2024-12-20 17:09:26,327 [INFO]: Epoch 1/250: loss: 0.7029, accuracy: 0.5083, val_loss: 0.6975, val_accuracy: 0.4625
2024-12-20 17:09:36,658 [INFO]: Epoch 250/250: loss: 0.2784, accuracy: 0.8667, val_loss: 0.3439, val_accuracy: 0.8125
2024-12-20 17:09:37,734 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=SGD, Layers=1...
2024-12-20 17:09:38,157 [INFO]: Epoch 1/500: loss: 0.5680, accuracy: 0.7125, val_loss: 0.3940, val_accuracy: 0.8000
2024-12-20 17:11:01,110 [INFO]: Epoch 500/500: loss: 0.0736, accuracy: 0.9667, val_loss: 0.1093, val_accuracy: 0.9625
2024-12-20 17:11:02,174 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=SGD, Layers=2...
2024-12-20 17:11:02,610 [INFO]: Epoch 1/500: loss: 0.6974, accuracy: 0.5958, val_loss: 0.6160, val_accuracy: 0.6625
2024-12-20 17:12:27,077 [INFO]: Epoch 500/500: loss: 0.0650, accuracy: 0.9625, val_loss: 0.1247, val_accuracy: 0.9375
2024-12-20 17:12:28,174 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=SGD, Layers=3...
2024-12-20 17:12:28,631 [INFO]: Epoch 1/500: loss: 0.7580, accuracy: 0.4583, val_loss: 0.7125, val_accuracy: 0.5375
2024-12-20 17:13:53,987 [INFO]: Epoch 500/500: loss: 0.0771, accuracy: 0.9667, val_loss: 0.1743, val_accuracy: 0.9250
2024-12-20 17:13:55,083 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=BGD, Layers=1...
2024-12-20 17:13:55,364 [INFO]: Epoch 1/500: loss: 1.1832, accuracy: 0.5000, val_loss: 1.1124, val_accuracy: 0.4625
2024-12-20 17:14:12,437 [INFO]: Epoch 500/500: loss: 0.3188, accuracy: 0.8417, val_loss: 0.3369, val_accuracy: 0.8250
2024-12-20 17:14:13,507 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=BGD, Layers=2...
2024-12-20 17:14:13,801 [INFO]: Epoch 1/500: loss: 0.7302, accuracy: 0.5000, val_loss: 0.7053, val_accuracy: 0.5375
2024-12-20 17:14:30,836 [INFO]: Epoch 500/500: loss: 0.3981, accuracy: 0.8083, val_loss: 0.3972, val_accuracy: 0.8125
2024-12-20 17:14:31,892 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=BGD, Layers=3...
2024-12-20 17:14:32,212 [INFO]: Epoch 1/500: loss: 0.7002, accuracy: 0.5000, val_loss: 0.7036, val_accuracy: 0.4625
2024-12-20 17:14:49,213 [INFO]: Epoch 500/500: loss: 0.6670, accuracy: 0.7583, val_loss: 0.6661, val_accuracy: 0.7875
2024-12-20 17:14:50,298 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=MBGD, Layers=1...
2024-12-20 17:14:50,612 [INFO]: Epoch 1/500: loss: 0.6475, accuracy: 0.6542, val_loss: 0.6275, val_accuracy: 0.8000
2024-12-20 17:15:10,405 [INFO]: Epoch 500/500: loss: 0.2734, accuracy: 0.8583, val_loss: 0.3380, val_accuracy: 0.8375
2024-12-20 17:15:11,466 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=MBGD, Layers=2...
2024-12-20 17:15:11,807 [INFO]: Epoch 1/500: loss: 0.7140, accuracy: 0.4542, val_loss: 0.6952, val_accuracy: 0.4375
2024-12-20 17:15:31,629 [INFO]: Epoch 500/500: loss: 0.2748, accuracy: 0.8625, val_loss: 0.3396, val_accuracy: 0.8250
2024-12-20 17:15:32,680 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=MBGD, Layers=3...
2024-12-20 17:15:33,038 [INFO]: Epoch 1/500: loss: 0.7195, accuracy: 0.5000, val_loss: 0.7074, val_accuracy: 0.4625
2024-12-20 17:15:52,898 [INFO]: Epoch 500/500: loss: 0.2776, accuracy: 0.8708, val_loss: 0.3398, val_accuracy: 0.8250
2024-12-20 17:15:53,976 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=SGD, Layers=1...
2024-12-20 17:15:54,380 [INFO]: Epoch 1/1000: loss: 0.5717, accuracy: 0.7000, val_loss: 0.3957, val_accuracy: 0.8000
2024-12-20 17:18:38,480 [INFO]: Epoch 1000/1000: loss: 0.0620, accuracy: 0.9708, val_loss: 0.1035, val_accuracy: 0.9625
2024-12-20 17:18:39,519 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=SGD, Layers=2...
2024-12-20 17:18:39,945 [INFO]: Epoch 1/1000: loss: 0.7418, accuracy: 0.5125, val_loss: 0.7627, val_accuracy: 0.4625
2024-12-20 17:21:26,559 [INFO]: Epoch 1000/1000: loss: 0.0498, accuracy: 0.9833, val_loss: 0.0814, val_accuracy: 0.9750
2024-12-20 17:21:27,618 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=SGD, Layers=3...
2024-12-20 17:21:28,072 [INFO]: Epoch 1/1000: loss: 0.7468, accuracy: 0.5375, val_loss: 0.7554, val_accuracy: 0.5375
2024-12-20 17:24:17,718 [INFO]: Epoch 1000/1000: loss: 0.0628, accuracy: 0.9750, val_loss: 0.1255, val_accuracy: 0.9625
2024-12-20 17:24:18,808 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=BGD, Layers=1...
2024-12-20 17:24:19,078 [INFO]: Epoch 1/1000: loss: 0.8073, accuracy: 0.5000, val_loss: 0.7899, val_accuracy: 0.4625
2024-12-20 17:24:52,830 [INFO]: Epoch 1000/1000: loss: 0.2774, accuracy: 0.8500, val_loss: 0.3259, val_accuracy: 0.8375
2024-12-20 17:24:53,865 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=BGD, Layers=2...
2024-12-20 17:24:54,587 [INFO]: Epoch 1/1000: loss: 0.8549, accuracy: 0.5000, val_loss: 0.7486, val_accuracy: 0.5375
2024-12-20 17:25:30,256 [INFO]: Epoch 1000/1000: loss: 0.2810, accuracy: 0.8542, val_loss: 0.3276, val_accuracy: 0.8500
2024-12-20 17:25:31,328 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=BGD, Layers=3...
2024-12-20 17:25:31,676 [INFO]: Epoch 1/1000: loss: 1.0347, accuracy: 0.5000, val_loss: 0.8620, val_accuracy: 0.5375
2024-12-20 17:26:06,684 [INFO]: Epoch 1000/1000: loss: 0.4386, accuracy: 0.8042, val_loss: 0.4346, val_accuracy: 0.8125
2024-12-20 17:26:07,785 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=MBGD, Layers=1...
2024-12-20 17:26:08,106 [INFO]: Epoch 1/1000: loss: 0.6885, accuracy: 0.5500, val_loss: 0.6763, val_accuracy: 0.5500
2024-12-20 17:26:48,435 [INFO]: Epoch 1000/1000: loss: 0.2720, accuracy: 0.8542, val_loss: 0.3379, val_accuracy: 0.8250
2024-12-20 17:26:49,501 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=MBGD, Layers=2...
2024-12-20 17:26:49,846 [INFO]: Epoch 1/1000: loss: 0.6900, accuracy: 0.5375, val_loss: 0.6840, val_accuracy: 0.5375
2024-12-20 17:27:30,150 [INFO]: Epoch 1000/1000: loss: 0.2698, accuracy: 0.8583, val_loss: 0.3338, val_accuracy: 0.8250
2024-12-20 17:27:31,226 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=MBGD, Layers=3...
2024-12-20 17:27:31,593 [INFO]: Epoch 1/1000: loss: 0.7038, accuracy: 0.4958, val_loss: 0.7004, val_accuracy: 0.4625
2024-12-20 17:28:11,906 [INFO]: Epoch 1000/1000: loss: 0.2704, accuracy: 0.8708, val_loss: 0.3350, val_accuracy: 0.8250
2024-12-20 17:28:13,009 [INFO]: ANN training complete.
2024-12-20 17:28:13,009 [INFO]: Training SVM: Kernel=linear, C=0.01, Degree=3, Gamma=scale...
2024-12-20 17:28:13,346 [INFO]: Training SVM: Kernel=linear, C=0.1, Degree=3, Gamma=scale...
2024-12-20 17:28:13,646 [INFO]: Training SVM: Kernel=linear, C=1, Degree=3, Gamma=scale...
2024-12-20 17:28:13,935 [INFO]: Training SVM: Kernel=linear, C=10, Degree=3, Gamma=scale...
2024-12-20 17:28:14,219 [INFO]: Training SVM: Kernel=linear, C=100, Degree=3, Gamma=scale...
2024-12-20 17:28:14,522 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=2, Gamma=scale...
2024-12-20 17:28:14,861 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=2, Gamma=auto...
2024-12-20 17:28:15,213 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=3, Gamma=scale...
2024-12-20 17:28:15,540 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=3, Gamma=auto...
2024-12-20 17:28:15,888 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=4, Gamma=scale...
2024-12-20 17:28:16,221 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=4, Gamma=auto...
2024-12-20 17:28:16,567 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=2, Gamma=scale...
2024-12-20 17:28:16,894 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=2, Gamma=auto...
2024-12-20 17:28:17,242 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=3, Gamma=scale...
2024-12-20 17:28:17,547 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=3, Gamma=auto...
2024-12-20 17:28:17,870 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=4, Gamma=scale...
2024-12-20 17:28:18,204 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=4, Gamma=auto...
2024-12-20 17:28:18,536 [INFO]: Training SVM: Kernel=poly, C=1, Degree=2, Gamma=scale...
2024-12-20 17:28:18,853 [INFO]: Training SVM: Kernel=poly, C=1, Degree=2, Gamma=auto...
2024-12-20 17:28:19,170 [INFO]: Training SVM: Kernel=poly, C=1, Degree=3, Gamma=scale...
2024-12-20 17:28:19,465 [INFO]: Training SVM: Kernel=poly, C=1, Degree=3, Gamma=auto...
2024-12-20 17:28:19,771 [INFO]: Training SVM: Kernel=poly, C=1, Degree=4, Gamma=scale...
2024-12-20 17:28:20,097 [INFO]: Training SVM: Kernel=poly, C=1, Degree=4, Gamma=auto...
2024-12-20 17:28:20,421 [INFO]: Training SVM: Kernel=poly, C=10, Degree=2, Gamma=scale...
2024-12-20 17:28:20,735 [INFO]: Training SVM: Kernel=poly, C=10, Degree=2, Gamma=auto...
2024-12-20 17:28:21,047 [INFO]: Training SVM: Kernel=poly, C=10, Degree=3, Gamma=scale...
2024-12-20 17:28:21,338 [INFO]: Training SVM: Kernel=poly, C=10, Degree=3, Gamma=auto...
2024-12-20 17:28:21,633 [INFO]: Training SVM: Kernel=poly, C=10, Degree=4, Gamma=scale...
2024-12-20 17:28:21,987 [INFO]: Training SVM: Kernel=poly, C=10, Degree=4, Gamma=auto...
2024-12-20 17:28:22,310 [INFO]: Training SVM: Kernel=rbf, C=0.01, Degree=3, Gamma=scale...
2024-12-20 17:28:22,769 [INFO]: Training SVM: Kernel=rbf, C=0.01, Degree=3, Gamma=auto...
2024-12-20 17:28:23,227 [INFO]: Training SVM: Kernel=rbf, C=0.01, Degree=3, Gamma=0.01...
2024-12-20 17:28:23,684 [INFO]: Training SVM: Kernel=rbf, C=0.01, Degree=3, Gamma=0.1...
2024-12-20 17:28:24,152 [INFO]: Training SVM: Kernel=rbf, C=0.01, Degree=3, Gamma=1...
2024-12-20 17:28:24,612 [INFO]: Training SVM: Kernel=rbf, C=0.1, Degree=3, Gamma=scale...
2024-12-20 17:28:24,981 [INFO]: Training SVM: Kernel=rbf, C=0.1, Degree=3, Gamma=auto...
2024-12-20 17:28:25,356 [INFO]: Training SVM: Kernel=rbf, C=0.1, Degree=3, Gamma=0.01...
2024-12-20 17:28:25,817 [INFO]: Training SVM: Kernel=rbf, C=0.1, Degree=3, Gamma=0.1...
2024-12-20 17:28:26,224 [INFO]: Training SVM: Kernel=rbf, C=0.1, Degree=3, Gamma=1...
2024-12-20 17:28:26,589 [INFO]: Training SVM: Kernel=rbf, C=1, Degree=3, Gamma=scale...
2024-12-20 17:28:26,902 [INFO]: Training SVM: Kernel=rbf, C=1, Degree=3, Gamma=auto...
2024-12-20 17:28:27,225 [INFO]: Training SVM: Kernel=rbf, C=1, Degree=3, Gamma=0.01...
2024-12-20 17:28:27,622 [INFO]: Training SVM: Kernel=rbf, C=1, Degree=3, Gamma=0.1...
2024-12-20 17:28:27,968 [INFO]: Training SVM: Kernel=rbf, C=1, Degree=3, Gamma=1...
2024-12-20 17:28:28,277 [INFO]: Training SVM: Kernel=rbf, C=10, Degree=3, Gamma=scale...
2024-12-20 17:28:28,562 [INFO]: Training SVM: Kernel=rbf, C=10, Degree=3, Gamma=auto...
2024-12-20 17:28:29,286 [INFO]: Training SVM: Kernel=rbf, C=10, Degree=3, Gamma=0.01...
2024-12-20 17:28:29,628 [INFO]: Training SVM: Kernel=rbf, C=10, Degree=3, Gamma=0.1...
2024-12-20 17:28:29,953 [INFO]: Training SVM: Kernel=rbf, C=10, Degree=3, Gamma=1...
2024-12-20 17:28:30,243 [INFO]: Training SVM: Kernel=rbf, C=100, Degree=3, Gamma=scale...
2024-12-20 17:28:30,532 [INFO]: Training SVM: Kernel=rbf, C=100, Degree=3, Gamma=auto...
2024-12-20 17:28:30,820 [INFO]: Training SVM: Kernel=rbf, C=100, Degree=3, Gamma=0.01...
2024-12-20 17:28:31,159 [INFO]: Training SVM: Kernel=rbf, C=100, Degree=3, Gamma=0.1...
2024-12-20 17:28:31,474 [INFO]: Training SVM: Kernel=rbf, C=100, Degree=3, Gamma=1...
2024-12-20 17:28:31,764 [INFO]: SVM training complete.
2024-12-20 17:28:31,764 [INFO]: 
Saving combined metrics...
2024-12-20 17:28:31,765 [INFO]: Combined metrics saved to train_results/combined_metrics.txt.
