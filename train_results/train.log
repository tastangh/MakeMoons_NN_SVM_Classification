2024-12-18 18:06:27,934 [INFO]: Trainer initialized.
2024-12-18 18:06:27,934 [INFO]: Creating and splitting the dataset...
2024-12-18 18:06:27,946 [INFO]: Visualizing the dataset...
2024-12-18 18:06:28,593 [INFO]: Data preparation complete.
2024-12-18 18:06:28,593 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=SGD, Layers=1...
2024-12-18 18:06:29,080 [INFO]: Epoch 1/50: loss: 0.7386, accuracy: 0.5000, val_loss: 0.7299, val_accuracy: 0.5375
2024-12-18 18:06:37,151 [INFO]: Epoch 50/50: loss: 0.7006, accuracy: 0.5208, val_loss: 0.7009, val_accuracy: 0.5125
2024-12-18 18:06:38,325 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=SGD, Layers=2...
2024-12-18 18:06:38,763 [INFO]: Epoch 1/50: loss: 0.7381, accuracy: 0.5000, val_loss: 0.7571, val_accuracy: 0.4625
2024-12-18 18:06:46,998 [INFO]: Epoch 50/50: loss: 0.6906, accuracy: 0.5000, val_loss: 0.6915, val_accuracy: 0.4625
2024-12-18 18:06:48,067 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=SGD, Layers=3...
2024-12-18 18:06:48,526 [INFO]: Epoch 1/50: loss: 0.6917, accuracy: 0.5000, val_loss: 0.6932, val_accuracy: 0.4625
2024-12-18 18:06:56,888 [INFO]: Epoch 50/50: loss: 0.6911, accuracy: 0.8042, val_loss: 0.6911, val_accuracy: 0.8125
2024-12-18 18:06:57,976 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=BGD, Layers=1...
2024-12-18 18:06:58,252 [INFO]: Epoch 1/50: loss: 0.6776, accuracy: 0.4958, val_loss: 0.6831, val_accuracy: 0.4625
2024-12-18 18:06:59,920 [INFO]: Epoch 50/50: loss: 0.6775, accuracy: 0.4958, val_loss: 0.6829, val_accuracy: 0.4625
2024-12-18 18:07:00,976 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=BGD, Layers=2...
2024-12-18 18:07:01,273 [INFO]: Epoch 1/50: loss: 0.7542, accuracy: 0.5000, val_loss: 0.7795, val_accuracy: 0.4625
2024-12-18 18:07:02,913 [INFO]: Epoch 50/50: loss: 0.7528, accuracy: 0.5000, val_loss: 0.7779, val_accuracy: 0.4625
2024-12-18 18:07:03,983 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=BGD, Layers=3...
2024-12-18 18:07:04,435 [INFO]: Epoch 1/50: loss: 0.6969, accuracy: 0.5000, val_loss: 0.7026, val_accuracy: 0.4625
2024-12-18 18:07:06,101 [INFO]: Epoch 50/50: loss: 0.6969, accuracy: 0.5000, val_loss: 0.7024, val_accuracy: 0.4625
2024-12-18 18:07:07,188 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=MBGD, Layers=1...
2024-12-18 18:07:07,507 [INFO]: Epoch 1/50: loss: 0.7521, accuracy: 0.5000, val_loss: 0.7657, val_accuracy: 0.4625
2024-12-18 18:07:09,465 [INFO]: Epoch 50/50: loss: 0.7483, accuracy: 0.5000, val_loss: 0.7608, val_accuracy: 0.4625
2024-12-18 18:07:10,541 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=MBGD, Layers=2...
2024-12-18 18:07:10,872 [INFO]: Epoch 1/50: loss: 0.7697, accuracy: 0.5000, val_loss: 0.7986, val_accuracy: 0.4625
2024-12-18 18:07:12,813 [INFO]: Epoch 50/50: loss: 0.7564, accuracy: 0.5000, val_loss: 0.7825, val_accuracy: 0.4625
2024-12-18 18:07:13,932 [INFO]: Training ANN: LR=0.0001, Epochs=50, Optimizer=MBGD, Layers=3...
2024-12-18 18:07:14,295 [INFO]: Epoch 1/50: loss: 0.6998, accuracy: 0.5000, val_loss: 0.6908, val_accuracy: 0.5375
2024-12-18 18:07:16,245 [INFO]: Epoch 50/50: loss: 0.6983, accuracy: 0.5000, val_loss: 0.6904, val_accuracy: 0.5375
2024-12-18 18:07:17,374 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=SGD, Layers=1...
2024-12-18 18:07:17,777 [INFO]: Epoch 1/250: loss: 0.6831, accuracy: 0.5000, val_loss: 0.6631, val_accuracy: 0.5375
2024-12-18 18:07:58,961 [INFO]: Epoch 250/250: loss: 0.5578, accuracy: 0.8042, val_loss: 0.5565, val_accuracy: 0.7750
2024-12-18 18:08:00,061 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=SGD, Layers=2...
2024-12-18 18:08:00,503 [INFO]: Epoch 1/250: loss: 0.6961, accuracy: 0.5000, val_loss: 0.7034, val_accuracy: 0.4625
2024-12-18 18:08:42,094 [INFO]: Epoch 250/250: loss: 0.6733, accuracy: 0.8208, val_loss: 0.6726, val_accuracy: 0.8000
2024-12-18 18:08:43,229 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=SGD, Layers=3...
2024-12-18 18:08:43,689 [INFO]: Epoch 1/250: loss: 0.7096, accuracy: 0.5000, val_loss: 0.6958, val_accuracy: 0.5375
2024-12-18 18:09:25,902 [INFO]: Epoch 250/250: loss: 0.6929, accuracy: 0.6000, val_loss: 0.6927, val_accuracy: 0.6750
2024-12-18 18:09:27,044 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=BGD, Layers=1...
2024-12-18 18:09:27,319 [INFO]: Epoch 1/250: loss: 0.6880, accuracy: 0.4708, val_loss: 0.6908, val_accuracy: 0.4625
2024-12-18 18:09:35,697 [INFO]: Epoch 250/250: loss: 0.6872, accuracy: 0.4667, val_loss: 0.6898, val_accuracy: 0.4625
2024-12-18 18:09:36,955 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=BGD, Layers=2...
2024-12-18 18:09:37,260 [INFO]: Epoch 1/250: loss: 0.7110, accuracy: 0.5000, val_loss: 0.6968, val_accuracy: 0.5375
2024-12-18 18:09:45,764 [INFO]: Epoch 250/250: loss: 0.7087, accuracy: 0.5000, val_loss: 0.6954, val_accuracy: 0.5375
2024-12-18 18:09:46,872 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=BGD, Layers=3...
2024-12-18 18:09:47,206 [INFO]: Epoch 1/250: loss: 0.8737, accuracy: 0.5000, val_loss: 0.8270, val_accuracy: 0.5375
2024-12-18 18:09:55,750 [INFO]: Epoch 250/250: loss: 0.8533, accuracy: 0.5000, val_loss: 0.8094, val_accuracy: 0.5375
2024-12-18 18:09:56,904 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=MBGD, Layers=1...
2024-12-18 18:09:57,235 [INFO]: Epoch 1/250: loss: 0.7138, accuracy: 0.5000, val_loss: 0.7247, val_accuracy: 0.4625
2024-12-18 18:10:07,150 [INFO]: Epoch 250/250: loss: 0.7024, accuracy: 0.5000, val_loss: 0.7091, val_accuracy: 0.4625
2024-12-18 18:10:08,255 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=MBGD, Layers=2...
2024-12-18 18:10:08,598 [INFO]: Epoch 1/250: loss: 0.7101, accuracy: 0.5000, val_loss: 0.6969, val_accuracy: 0.5375
2024-12-18 18:10:18,464 [INFO]: Epoch 250/250: loss: 0.7001, accuracy: 0.5000, val_loss: 0.6920, val_accuracy: 0.5375
2024-12-18 18:10:19,595 [INFO]: Training ANN: LR=0.0001, Epochs=250, Optimizer=MBGD, Layers=3...
2024-12-18 18:10:19,964 [INFO]: Epoch 1/250: loss: 0.7449, accuracy: 0.5000, val_loss: 0.7208, val_accuracy: 0.5375
2024-12-18 18:10:29,870 [INFO]: Epoch 250/250: loss: 0.7116, accuracy: 0.5000, val_loss: 0.6976, val_accuracy: 0.5375
2024-12-18 18:10:31,006 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=SGD, Layers=1...
2024-12-18 18:10:31,415 [INFO]: Epoch 1/500: loss: 0.6590, accuracy: 0.7625, val_loss: 0.6556, val_accuracy: 0.7750
2024-12-18 18:11:53,823 [INFO]: Epoch 500/500: loss: 0.4825, accuracy: 0.8083, val_loss: 0.4825, val_accuracy: 0.7875
2024-12-18 18:11:54,929 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=SGD, Layers=2...
2024-12-18 18:11:55,370 [INFO]: Epoch 1/500: loss: 0.9086, accuracy: 0.5000, val_loss: 0.8484, val_accuracy: 0.5375
2024-12-18 18:13:19,001 [INFO]: Epoch 500/500: loss: 0.6512, accuracy: 0.7583, val_loss: 0.6504, val_accuracy: 0.7500
2024-12-18 18:13:20,122 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=SGD, Layers=3...
2024-12-18 18:13:20,781 [INFO]: Epoch 1/500: loss: 0.7076, accuracy: 0.5000, val_loss: 0.7196, val_accuracy: 0.4625
2024-12-18 18:14:46,346 [INFO]: Epoch 500/500: loss: 0.6901, accuracy: 0.8708, val_loss: 0.6900, val_accuracy: 0.8500
2024-12-18 18:14:47,497 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=BGD, Layers=1...
2024-12-18 18:14:47,778 [INFO]: Epoch 1/500: loss: 0.7015, accuracy: 0.5000, val_loss: 0.7089, val_accuracy: 0.4625
2024-12-18 18:15:04,725 [INFO]: Epoch 500/500: loss: 0.6988, accuracy: 0.5000, val_loss: 0.7053, val_accuracy: 0.4625
2024-12-18 18:15:05,830 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=BGD, Layers=2...
2024-12-18 18:15:06,141 [INFO]: Epoch 1/500: loss: 0.7365, accuracy: 0.5000, val_loss: 0.7134, val_accuracy: 0.5375
2024-12-18 18:15:23,043 [INFO]: Epoch 500/500: loss: 0.7253, accuracy: 0.5000, val_loss: 0.7051, val_accuracy: 0.5375
2024-12-18 18:15:24,163 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=BGD, Layers=3...
2024-12-18 18:15:24,488 [INFO]: Epoch 1/500: loss: 0.7470, accuracy: 0.5000, val_loss: 0.7221, val_accuracy: 0.5375
2024-12-18 18:15:41,313 [INFO]: Epoch 500/500: loss: 0.7349, accuracy: 0.5000, val_loss: 0.7129, val_accuracy: 0.5375
2024-12-18 18:15:42,462 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=MBGD, Layers=1...
2024-12-18 18:15:42,785 [INFO]: Epoch 1/500: loss: 0.6666, accuracy: 0.6667, val_loss: 0.6695, val_accuracy: 0.6625
2024-12-18 18:16:02,477 [INFO]: Epoch 500/500: loss: 0.6572, accuracy: 0.6125, val_loss: 0.6570, val_accuracy: 0.6125
2024-12-18 18:16:03,641 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=MBGD, Layers=2...
2024-12-18 18:16:03,984 [INFO]: Epoch 1/500: loss: 0.7964, accuracy: 0.5000, val_loss: 0.8310, val_accuracy: 0.4625
2024-12-18 18:16:23,717 [INFO]: Epoch 500/500: loss: 0.7063, accuracy: 0.5000, val_loss: 0.7190, val_accuracy: 0.4625
2024-12-18 18:16:24,942 [INFO]: Training ANN: LR=0.0001, Epochs=500, Optimizer=MBGD, Layers=3...
2024-12-18 18:16:25,304 [INFO]: Epoch 1/500: loss: 0.6946, accuracy: 0.5000, val_loss: 0.6936, val_accuracy: 0.5375
2024-12-18 18:16:45,107 [INFO]: Epoch 500/500: loss: 0.6945, accuracy: 0.5000, val_loss: 0.6940, val_accuracy: 0.5375
2024-12-18 18:16:46,356 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=SGD, Layers=1...
2024-12-18 18:16:46,758 [INFO]: Epoch 1/1000: loss: 0.7296, accuracy: 0.5000, val_loss: 0.6972, val_accuracy: 0.5375
2024-12-18 18:19:31,648 [INFO]: Epoch 1000/1000: loss: 0.3647, accuracy: 0.8208, val_loss: 0.3730, val_accuracy: 0.8125
2024-12-18 18:19:32,879 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=SGD, Layers=2...
2024-12-18 18:19:33,512 [INFO]: Epoch 1/1000: loss: 0.7403, accuracy: 0.5000, val_loss: 0.7607, val_accuracy: 0.4625
2024-12-18 18:22:22,286 [INFO]: Epoch 1000/1000: loss: 0.6178, accuracy: 0.8042, val_loss: 0.6173, val_accuracy: 0.8000
2024-12-18 18:22:23,516 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=SGD, Layers=3...
2024-12-18 18:22:23,991 [INFO]: Epoch 1/1000: loss: 1.0050, accuracy: 0.5000, val_loss: 0.9292, val_accuracy: 0.5375
2024-12-18 18:25:15,280 [INFO]: Epoch 1000/1000: loss: 0.6900, accuracy: 0.7583, val_loss: 0.6899, val_accuracy: 0.7625
2024-12-18 18:25:16,551 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=BGD, Layers=1...
2024-12-18 18:25:16,829 [INFO]: Epoch 1/1000: loss: 0.7062, accuracy: 0.5000, val_loss: 0.6912, val_accuracy: 0.5375
2024-12-18 18:25:50,707 [INFO]: Epoch 1000/1000: loss: 0.6972, accuracy: 0.5000, val_loss: 0.6851, val_accuracy: 0.5375
2024-12-18 18:25:51,928 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=BGD, Layers=2...
2024-12-18 18:25:52,242 [INFO]: Epoch 1/1000: loss: 0.7050, accuracy: 0.5000, val_loss: 0.6923, val_accuracy: 0.5375
2024-12-18 18:26:26,033 [INFO]: Epoch 1000/1000: loss: 0.6993, accuracy: 0.5000, val_loss: 0.6893, val_accuracy: 0.5375
2024-12-18 18:26:27,253 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=BGD, Layers=3...
2024-12-18 18:26:27,573 [INFO]: Epoch 1/1000: loss: 0.8976, accuracy: 0.5000, val_loss: 0.9472, val_accuracy: 0.4625
2024-12-18 18:27:01,210 [INFO]: Epoch 1000/1000: loss: 0.8230, accuracy: 0.5000, val_loss: 0.8620, val_accuracy: 0.4625
2024-12-18 18:27:02,449 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=MBGD, Layers=1...
2024-12-18 18:27:02,769 [INFO]: Epoch 1/1000: loss: 0.7373, accuracy: 0.5000, val_loss: 0.7523, val_accuracy: 0.4625
2024-12-18 18:27:42,060 [INFO]: Epoch 1000/1000: loss: 0.7020, accuracy: 0.3625, val_loss: 0.7048, val_accuracy: 0.3375
2024-12-18 18:27:43,295 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=MBGD, Layers=2...
2024-12-18 18:27:43,636 [INFO]: Epoch 1/1000: loss: 0.8018, accuracy: 0.5000, val_loss: 0.8370, val_accuracy: 0.4625
2024-12-18 18:28:23,043 [INFO]: Epoch 1000/1000: loss: 0.6938, accuracy: 0.5000, val_loss: 0.6971, val_accuracy: 0.4625
2024-12-18 18:28:24,266 [INFO]: Training ANN: LR=0.0001, Epochs=1000, Optimizer=MBGD, Layers=3...
2024-12-18 18:28:24,623 [INFO]: Epoch 1/1000: loss: 0.7818, accuracy: 0.5000, val_loss: 0.7493, val_accuracy: 0.5375
2024-12-18 18:29:04,127 [INFO]: Epoch 1000/1000: loss: 0.6920, accuracy: 0.5000, val_loss: 0.6879, val_accuracy: 0.5375
2024-12-18 18:29:05,375 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=SGD, Layers=1...
2024-12-18 18:29:05,786 [INFO]: Epoch 1/50: loss: 0.6721, accuracy: 0.6417, val_loss: 0.6703, val_accuracy: 0.6875
2024-12-18 18:29:13,919 [INFO]: Epoch 50/50: loss: 0.4823, accuracy: 0.8083, val_loss: 0.4807, val_accuracy: 0.8000
2024-12-18 18:29:15,367 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=SGD, Layers=2...
2024-12-18 18:29:15,824 [INFO]: Epoch 1/50: loss: 0.7945, accuracy: 0.5000, val_loss: 0.7193, val_accuracy: 0.5375
2024-12-18 18:29:24,191 [INFO]: Epoch 50/50: loss: 0.6635, accuracy: 0.7875, val_loss: 0.6614, val_accuracy: 0.7750
2024-12-18 18:29:25,432 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=SGD, Layers=3...
2024-12-18 18:29:25,910 [INFO]: Epoch 1/50: loss: 0.6960, accuracy: 0.4583, val_loss: 0.6972, val_accuracy: 0.4625
2024-12-18 18:29:34,394 [INFO]: Epoch 50/50: loss: 0.6934, accuracy: 0.5083, val_loss: 0.6919, val_accuracy: 0.5375
2024-12-18 18:29:35,653 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=BGD, Layers=1...
2024-12-18 18:29:35,938 [INFO]: Epoch 1/50: loss: 0.7016, accuracy: 0.4125, val_loss: 0.6996, val_accuracy: 0.4250
2024-12-18 18:29:37,615 [INFO]: Epoch 50/50: loss: 0.7001, accuracy: 0.4042, val_loss: 0.6984, val_accuracy: 0.4125
2024-12-18 18:29:38,853 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=BGD, Layers=2...
2024-12-18 18:29:39,148 [INFO]: Epoch 1/50: loss: 0.8185, accuracy: 0.5000, val_loss: 0.8561, val_accuracy: 0.4625
2024-12-18 18:29:40,814 [INFO]: Epoch 50/50: loss: 0.7915, accuracy: 0.5000, val_loss: 0.8247, val_accuracy: 0.4625
2024-12-18 18:29:42,057 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=BGD, Layers=3...
2024-12-18 18:29:42,373 [INFO]: Epoch 1/50: loss: 0.7484, accuracy: 0.5000, val_loss: 0.7734, val_accuracy: 0.4625
2024-12-18 18:29:44,022 [INFO]: Epoch 50/50: loss: 0.7362, accuracy: 0.5000, val_loss: 0.7583, val_accuracy: 0.4625
2024-12-18 18:29:45,253 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=MBGD, Layers=1...
2024-12-18 18:29:45,563 [INFO]: Epoch 1/50: loss: 0.7123, accuracy: 0.5000, val_loss: 0.6968, val_accuracy: 0.5375
2024-12-18 18:29:47,515 [INFO]: Epoch 50/50: loss: 0.6852, accuracy: 0.5000, val_loss: 0.6791, val_accuracy: 0.5375
2024-12-18 18:29:48,722 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=MBGD, Layers=2...
2024-12-18 18:29:49,056 [INFO]: Epoch 1/50: loss: 0.8261, accuracy: 0.5000, val_loss: 0.8623, val_accuracy: 0.4625
2024-12-18 18:29:51,001 [INFO]: Epoch 50/50: loss: 0.7068, accuracy: 0.5000, val_loss: 0.7204, val_accuracy: 0.4625
2024-12-18 18:29:52,243 [INFO]: Training ANN: LR=0.001, Epochs=50, Optimizer=MBGD, Layers=3...
2024-12-18 18:29:52,596 [INFO]: Epoch 1/50: loss: 0.6909, accuracy: 0.5000, val_loss: 0.6913, val_accuracy: 0.4625
2024-12-18 18:29:54,540 [INFO]: Epoch 50/50: loss: 0.6908, accuracy: 0.8250, val_loss: 0.6909, val_accuracy: 0.8125
2024-12-18 18:29:55,795 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=SGD, Layers=1...
2024-12-18 18:29:56,209 [INFO]: Epoch 1/250: loss: 0.8684, accuracy: 0.5000, val_loss: 0.7693, val_accuracy: 0.5375
2024-12-18 18:30:37,298 [INFO]: Epoch 250/250: loss: 0.2717, accuracy: 0.8667, val_loss: 0.2960, val_accuracy: 0.8500
2024-12-18 18:30:38,745 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=SGD, Layers=2...
2024-12-18 18:30:39,188 [INFO]: Epoch 1/250: loss: 0.6949, accuracy: 0.5000, val_loss: 0.6947, val_accuracy: 0.4625
2024-12-18 18:31:21,482 [INFO]: Epoch 250/250: loss: 0.3312, accuracy: 0.8375, val_loss: 0.3440, val_accuracy: 0.8500
2024-12-18 18:31:22,738 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=SGD, Layers=3...
2024-12-18 18:31:23,202 [INFO]: Epoch 1/250: loss: 0.7034, accuracy: 0.5000, val_loss: 0.6917, val_accuracy: 0.5375
2024-12-18 18:32:05,905 [INFO]: Epoch 250/250: loss: 0.6773, accuracy: 0.7542, val_loss: 0.6749, val_accuracy: 0.8250
2024-12-18 18:32:07,184 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=BGD, Layers=1...
2024-12-18 18:32:07,467 [INFO]: Epoch 1/250: loss: 0.6722, accuracy: 0.5000, val_loss: 0.6626, val_accuracy: 0.5375
2024-12-18 18:32:15,955 [INFO]: Epoch 250/250: loss: 0.6615, accuracy: 0.5000, val_loss: 0.6556, val_accuracy: 0.5375
2024-12-18 18:32:17,204 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=BGD, Layers=2...
2024-12-18 18:32:17,508 [INFO]: Epoch 1/250: loss: 0.8199, accuracy: 0.5000, val_loss: 0.8580, val_accuracy: 0.4625
2024-12-18 18:32:25,951 [INFO]: Epoch 250/250: loss: 0.7284, accuracy: 0.5000, val_loss: 0.7492, val_accuracy: 0.4625
2024-12-18 18:32:27,167 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=BGD, Layers=3...
2024-12-18 18:32:27,500 [INFO]: Epoch 1/250: loss: 0.7655, accuracy: 0.5000, val_loss: 0.7364, val_accuracy: 0.5375
2024-12-18 18:32:35,932 [INFO]: Epoch 250/250: loss: 0.7127, accuracy: 0.5000, val_loss: 0.6979, val_accuracy: 0.5375
2024-12-18 18:32:37,166 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=MBGD, Layers=1...
2024-12-18 18:32:37,493 [INFO]: Epoch 1/250: loss: 0.7458, accuracy: 0.5000, val_loss: 0.7314, val_accuracy: 0.5375
2024-12-18 18:32:47,317 [INFO]: Epoch 250/250: loss: 0.6780, accuracy: 0.6292, val_loss: 0.6769, val_accuracy: 0.6500
2024-12-18 18:32:48,554 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=MBGD, Layers=2...
2024-12-18 18:32:48,886 [INFO]: Epoch 1/250: loss: 0.7067, accuracy: 0.5000, val_loss: 0.7001, val_accuracy: 0.5375
2024-12-18 18:32:58,762 [INFO]: Epoch 250/250: loss: 0.6978, accuracy: 0.1375, val_loss: 0.6975, val_accuracy: 0.1750
2024-12-18 18:32:59,997 [INFO]: Training ANN: LR=0.001, Epochs=250, Optimizer=MBGD, Layers=3...
2024-12-18 18:33:00,364 [INFO]: Epoch 1/250: loss: 0.7201, accuracy: 0.5000, val_loss: 0.7018, val_accuracy: 0.5375
2024-12-18 18:33:10,256 [INFO]: Epoch 250/250: loss: 0.6917, accuracy: 0.8083, val_loss: 0.6917, val_accuracy: 0.8000
2024-12-18 18:33:11,510 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=SGD, Layers=1...
2024-12-18 18:33:11,921 [INFO]: Epoch 1/500: loss: 0.7535, accuracy: 0.5000, val_loss: 0.7139, val_accuracy: 0.5375
2024-12-18 18:34:34,300 [INFO]: Epoch 500/500: loss: 0.2362, accuracy: 0.8917, val_loss: 0.2721, val_accuracy: 0.8625
2024-12-18 18:34:35,513 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=SGD, Layers=2...
2024-12-18 18:34:35,945 [INFO]: Epoch 1/500: loss: 0.7309, accuracy: 0.5000, val_loss: 0.7253, val_accuracy: 0.4625
2024-12-18 18:35:59,484 [INFO]: Epoch 500/500: loss: 0.2353, accuracy: 0.8958, val_loss: 0.2730, val_accuracy: 0.8625
2024-12-18 18:36:00,965 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=SGD, Layers=3...
2024-12-18 18:36:01,454 [INFO]: Epoch 1/500: loss: 0.7386, accuracy: 0.5000, val_loss: 0.6984, val_accuracy: 0.5375
2024-12-18 18:37:27,380 [INFO]: Epoch 500/500: loss: 0.2996, accuracy: 0.8500, val_loss: 0.3209, val_accuracy: 0.8500
2024-12-18 18:37:28,639 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=BGD, Layers=1...
2024-12-18 18:37:28,922 [INFO]: Epoch 1/500: loss: 0.9134, accuracy: 0.5000, val_loss: 0.9646, val_accuracy: 0.4625
2024-12-18 18:37:45,930 [INFO]: Epoch 500/500: loss: 0.7316, accuracy: 0.5000, val_loss: 0.7488, val_accuracy: 0.4625
2024-12-18 18:37:47,176 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=BGD, Layers=2...
2024-12-18 18:37:47,480 [INFO]: Epoch 1/500: loss: 0.7442, accuracy: 0.5000, val_loss: 0.7183, val_accuracy: 0.5375
2024-12-18 18:38:04,434 [INFO]: Epoch 500/500: loss: 0.6894, accuracy: 0.5000, val_loss: 0.6824, val_accuracy: 0.5375
2024-12-18 18:38:05,682 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=BGD, Layers=3...
2024-12-18 18:38:06,014 [INFO]: Epoch 1/500: loss: 0.7679, accuracy: 0.5000, val_loss: 0.7382, val_accuracy: 0.5375
2024-12-18 18:38:22,975 [INFO]: Epoch 500/500: loss: 0.6980, accuracy: 0.5000, val_loss: 0.6903, val_accuracy: 0.5375
2024-12-18 18:38:24,230 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=MBGD, Layers=1...
2024-12-18 18:38:24,549 [INFO]: Epoch 1/500: loss: 0.7525, accuracy: 0.5000, val_loss: 0.7718, val_accuracy: 0.4625
2024-12-18 18:38:44,281 [INFO]: Epoch 500/500: loss: 0.6361, accuracy: 0.8375, val_loss: 0.6365, val_accuracy: 0.8125
2024-12-18 18:38:45,598 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=MBGD, Layers=2...
2024-12-18 18:38:45,937 [INFO]: Epoch 1/500: loss: 0.8300, accuracy: 0.5000, val_loss: 0.8673, val_accuracy: 0.4625
2024-12-18 18:39:05,659 [INFO]: Epoch 500/500: loss: 0.6810, accuracy: 0.8542, val_loss: 0.6806, val_accuracy: 0.8500
2024-12-18 18:39:07,108 [INFO]: Training ANN: LR=0.001, Epochs=500, Optimizer=MBGD, Layers=3...
2024-12-18 18:39:07,473 [INFO]: Epoch 1/500: loss: 0.6932, accuracy: 0.5000, val_loss: 0.6964, val_accuracy: 0.4625
2024-12-18 18:39:27,252 [INFO]: Epoch 500/500: loss: 0.6914, accuracy: 0.6417, val_loss: 0.6913, val_accuracy: 0.7125
2024-12-18 18:39:28,721 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=SGD, Layers=1...
2024-12-18 18:39:29,127 [INFO]: Epoch 1/1000: loss: 0.6774, accuracy: 0.5000, val_loss: 0.6467, val_accuracy: 0.5375
2024-12-18 18:42:14,142 [INFO]: Epoch 1000/1000: loss: 0.2287, accuracy: 0.8958, val_loss: 0.2723, val_accuracy: 0.8625
2024-12-18 18:42:15,604 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=SGD, Layers=2...
2024-12-18 18:42:16,041 [INFO]: Epoch 1/1000: loss: 0.7156, accuracy: 0.5000, val_loss: 0.7168, val_accuracy: 0.4625
2024-12-18 18:45:03,262 [INFO]: Epoch 1000/1000: loss: 0.2313, accuracy: 0.8958, val_loss: 0.2770, val_accuracy: 0.8625
2024-12-18 18:45:04,714 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=SGD, Layers=3...
2024-12-18 18:45:05,176 [INFO]: Epoch 1/1000: loss: 0.7196, accuracy: 0.5000, val_loss: 0.7172, val_accuracy: 0.4625
2024-12-18 18:47:54,595 [INFO]: Epoch 1000/1000: loss: 0.2321, accuracy: 0.8917, val_loss: 0.2776, val_accuracy: 0.8750
2024-12-18 18:47:56,082 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=BGD, Layers=1...
2024-12-18 18:47:56,636 [INFO]: Epoch 1/1000: loss: 0.8019, accuracy: 0.5000, val_loss: 0.8344, val_accuracy: 0.4625
2024-12-18 18:48:31,421 [INFO]: Epoch 1000/1000: loss: 0.6987, accuracy: 0.5000, val_loss: 0.7037, val_accuracy: 0.4625
2024-12-18 18:48:32,872 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=BGD, Layers=2...
2024-12-18 18:48:33,187 [INFO]: Epoch 1/1000: loss: 0.7516, accuracy: 0.5000, val_loss: 0.7275, val_accuracy: 0.5375
2024-12-18 18:49:07,551 [INFO]: Epoch 1000/1000: loss: 0.6983, accuracy: 0.5000, val_loss: 0.6970, val_accuracy: 0.5375
2024-12-18 18:49:09,013 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=BGD, Layers=3...
2024-12-18 18:49:09,350 [INFO]: Epoch 1/1000: loss: 0.8533, accuracy: 0.5000, val_loss: 0.8960, val_accuracy: 0.4625
2024-12-18 18:49:43,406 [INFO]: Epoch 1000/1000: loss: 0.6948, accuracy: 0.5000, val_loss: 0.6978, val_accuracy: 0.4625
2024-12-18 18:49:44,898 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=MBGD, Layers=1...
2024-12-18 18:49:45,215 [INFO]: Epoch 1/1000: loss: 0.6765, accuracy: 0.5000, val_loss: 0.6821, val_accuracy: 0.4625
2024-12-18 18:50:24,964 [INFO]: Epoch 1000/1000: loss: 0.5142, accuracy: 0.8208, val_loss: 0.5135, val_accuracy: 0.8250
2024-12-18 18:50:26,416 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=MBGD, Layers=2...
2024-12-18 18:50:26,756 [INFO]: Epoch 1/1000: loss: 0.7690, accuracy: 0.5000, val_loss: 0.7366, val_accuracy: 0.5375
2024-12-18 18:51:06,516 [INFO]: Epoch 1000/1000: loss: 0.6691, accuracy: 0.7542, val_loss: 0.6688, val_accuracy: 0.7625
2024-12-18 18:51:07,964 [INFO]: Training ANN: LR=0.001, Epochs=1000, Optimizer=MBGD, Layers=3...
2024-12-18 18:51:08,328 [INFO]: Epoch 1/1000: loss: 0.7897, accuracy: 0.5000, val_loss: 0.7545, val_accuracy: 0.5375
2024-12-18 18:51:48,016 [INFO]: Epoch 1000/1000: loss: 0.6904, accuracy: 0.7875, val_loss: 0.6904, val_accuracy: 0.8000
2024-12-18 18:51:49,497 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=SGD, Layers=1...
2024-12-18 18:51:49,902 [INFO]: Epoch 1/50: loss: 0.7025, accuracy: 0.5458, val_loss: 0.6741, val_accuracy: 0.4625
2024-12-18 18:51:58,036 [INFO]: Epoch 50/50: loss: 0.2393, accuracy: 0.8917, val_loss: 0.2712, val_accuracy: 0.8625
2024-12-18 18:51:59,495 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=SGD, Layers=2...
2024-12-18 18:51:59,927 [INFO]: Epoch 1/50: loss: 0.6852, accuracy: 0.5417, val_loss: 0.6717, val_accuracy: 0.5375
2024-12-18 18:52:08,175 [INFO]: Epoch 50/50: loss: 0.2376, accuracy: 0.8917, val_loss: 0.2787, val_accuracy: 0.8500
2024-12-18 18:52:09,630 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=SGD, Layers=3...
2024-12-18 18:52:10,091 [INFO]: Epoch 1/50: loss: 0.7026, accuracy: 0.4833, val_loss: 0.6902, val_accuracy: 0.5375
2024-12-18 18:52:18,447 [INFO]: Epoch 50/50: loss: 0.2976, accuracy: 0.8583, val_loss: 0.3197, val_accuracy: 0.8500
2024-12-18 18:52:19,918 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=BGD, Layers=1...
2024-12-18 18:52:20,190 [INFO]: Epoch 1/50: loss: 0.7424, accuracy: 0.5000, val_loss: 0.7248, val_accuracy: 0.5375
2024-12-18 18:52:21,843 [INFO]: Epoch 50/50: loss: 0.7144, accuracy: 0.5000, val_loss: 0.7079, val_accuracy: 0.5375
2024-12-18 18:52:23,263 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=BGD, Layers=2...
2024-12-18 18:52:23,558 [INFO]: Epoch 1/50: loss: 0.7003, accuracy: 0.5000, val_loss: 0.6942, val_accuracy: 0.5375
2024-12-18 18:52:25,223 [INFO]: Epoch 50/50: loss: 0.6963, accuracy: 0.5000, val_loss: 0.6943, val_accuracy: 0.5375
2024-12-18 18:52:26,659 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=BGD, Layers=3...
2024-12-18 18:52:27,263 [INFO]: Epoch 1/50: loss: 0.7089, accuracy: 0.5000, val_loss: 0.7208, val_accuracy: 0.4625
2024-12-18 18:52:29,029 [INFO]: Epoch 50/50: loss: 0.6946, accuracy: 0.5000, val_loss: 0.6978, val_accuracy: 0.4625
2024-12-18 18:52:30,551 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=MBGD, Layers=1...
2024-12-18 18:52:30,892 [INFO]: Epoch 1/50: loss: 0.6926, accuracy: 0.5000, val_loss: 0.6814, val_accuracy: 0.5375
2024-12-18 18:52:32,904 [INFO]: Epoch 50/50: loss: 0.6166, accuracy: 0.7792, val_loss: 0.6148, val_accuracy: 0.7750
2024-12-18 18:52:34,339 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=MBGD, Layers=2...
2024-12-18 18:52:34,689 [INFO]: Epoch 1/50: loss: 0.7689, accuracy: 0.5000, val_loss: 0.7778, val_accuracy: 0.4625
2024-12-18 18:52:36,700 [INFO]: Epoch 50/50: loss: 0.6929, accuracy: 0.4708, val_loss: 0.6933, val_accuracy: 0.4625
2024-12-18 18:52:38,150 [INFO]: Training ANN: LR=0.01, Epochs=50, Optimizer=MBGD, Layers=3...
2024-12-18 18:52:38,515 [INFO]: Epoch 1/50: loss: 0.6932, accuracy: 0.5000, val_loss: 0.6889, val_accuracy: 0.5375
2024-12-18 18:52:40,504 [INFO]: Epoch 50/50: loss: 0.6908, accuracy: 0.6417, val_loss: 0.6902, val_accuracy: 0.7250
2024-12-18 18:52:41,992 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=SGD, Layers=1...
2024-12-18 18:52:42,406 [INFO]: Epoch 1/250: loss: 0.6751, accuracy: 0.6000, val_loss: 0.6369, val_accuracy: 0.7375
2024-12-18 18:53:23,758 [INFO]: Epoch 250/250: loss: 0.2320, accuracy: 0.9000, val_loss: 0.2745, val_accuracy: 0.8625
2024-12-18 18:53:25,204 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=SGD, Layers=2...
2024-12-18 18:53:25,643 [INFO]: Epoch 1/250: loss: 0.6968, accuracy: 0.4917, val_loss: 0.7089, val_accuracy: 0.4625
2024-12-18 18:54:07,696 [INFO]: Epoch 250/250: loss: 0.2368, accuracy: 0.8792, val_loss: 0.2773, val_accuracy: 0.8750
2024-12-18 18:54:09,161 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=SGD, Layers=3...
2024-12-18 18:54:09,624 [INFO]: Epoch 1/250: loss: 0.6986, accuracy: 0.5000, val_loss: 0.7204, val_accuracy: 0.4625
2024-12-18 18:54:52,007 [INFO]: Epoch 250/250: loss: 0.2414, accuracy: 0.8750, val_loss: 0.2791, val_accuracy: 0.8625
2024-12-18 18:54:53,484 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=BGD, Layers=1...
2024-12-18 18:54:53,759 [INFO]: Epoch 1/250: loss: 0.8374, accuracy: 0.5000, val_loss: 0.7887, val_accuracy: 0.5375
2024-12-18 18:55:02,134 [INFO]: Epoch 250/250: loss: 0.6237, accuracy: 0.7833, val_loss: 0.6226, val_accuracy: 0.7750
2024-12-18 18:55:03,587 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=BGD, Layers=2...
2024-12-18 18:55:03,882 [INFO]: Epoch 1/250: loss: 0.7823, accuracy: 0.5000, val_loss: 0.7482, val_accuracy: 0.5375
2024-12-18 18:55:12,247 [INFO]: Epoch 250/250: loss: 0.6940, accuracy: 0.5542, val_loss: 0.6941, val_accuracy: 0.5375
2024-12-18 18:55:13,702 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=BGD, Layers=3...
2024-12-18 18:55:14,022 [INFO]: Epoch 1/250: loss: 0.7289, accuracy: 0.5000, val_loss: 0.7467, val_accuracy: 0.4625
2024-12-18 18:55:22,410 [INFO]: Epoch 250/250: loss: 0.6938, accuracy: 0.2333, val_loss: 0.6938, val_accuracy: 0.2500
2024-12-18 18:55:23,896 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=MBGD, Layers=1...
2024-12-18 18:55:24,211 [INFO]: Epoch 1/250: loss: 0.7340, accuracy: 0.5000, val_loss: 0.7141, val_accuracy: 0.5375
2024-12-18 18:55:34,038 [INFO]: Epoch 250/250: loss: 0.4033, accuracy: 0.8208, val_loss: 0.4073, val_accuracy: 0.8250
2024-12-18 18:55:35,479 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=MBGD, Layers=2...
2024-12-18 18:55:35,810 [INFO]: Epoch 1/250: loss: 0.7526, accuracy: 0.5000, val_loss: 0.7642, val_accuracy: 0.4625
2024-12-18 18:55:45,670 [INFO]: Epoch 250/250: loss: 0.6379, accuracy: 0.8000, val_loss: 0.6367, val_accuracy: 0.8000
2024-12-18 18:55:47,127 [INFO]: Training ANN: LR=0.01, Epochs=250, Optimizer=MBGD, Layers=3...
2024-12-18 18:55:47,490 [INFO]: Epoch 1/250: loss: 0.8392, accuracy: 0.5000, val_loss: 0.8456, val_accuracy: 0.4625
2024-12-18 18:55:57,385 [INFO]: Epoch 250/250: loss: 0.6864, accuracy: 0.7875, val_loss: 0.6870, val_accuracy: 0.4625
2024-12-18 18:55:59,184 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=SGD, Layers=1...
2024-12-18 18:55:59,624 [INFO]: Epoch 1/500: loss: 0.6999, accuracy: 0.5250, val_loss: 0.6611, val_accuracy: 0.7625
2024-12-18 18:57:23,192 [INFO]: Epoch 500/500: loss: 0.2318, accuracy: 0.8917, val_loss: 0.2742, val_accuracy: 0.8625
2024-12-18 18:57:24,646 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=SGD, Layers=2...
2024-12-18 18:57:25,091 [INFO]: Epoch 1/500: loss: 0.7054, accuracy: 0.5417, val_loss: 0.7113, val_accuracy: 0.4625
2024-12-18 18:58:49,955 [INFO]: Epoch 500/500: loss: 0.2339, accuracy: 0.8958, val_loss: 0.2821, val_accuracy: 0.8625
2024-12-18 18:58:51,430 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=SGD, Layers=3...
2024-12-18 18:58:51,900 [INFO]: Epoch 1/500: loss: 0.7046, accuracy: 0.4458, val_loss: 0.6879, val_accuracy: 0.5375
2024-12-18 19:00:17,768 [INFO]: Epoch 500/500: loss: 0.2307, accuracy: 0.8833, val_loss: 0.2682, val_accuracy: 0.8625
2024-12-18 19:00:19,255 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=BGD, Layers=1...
2024-12-18 19:00:19,534 [INFO]: Epoch 1/500: loss: 0.7253, accuracy: 0.5000, val_loss: 0.6993, val_accuracy: 0.5375
2024-12-18 19:00:36,527 [INFO]: Epoch 500/500: loss: 0.5743, accuracy: 0.8000, val_loss: 0.5727, val_accuracy: 0.7750
2024-12-18 19:00:37,983 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=BGD, Layers=2...
2024-12-18 19:00:38,281 [INFO]: Epoch 1/500: loss: 0.6947, accuracy: 0.5000, val_loss: 0.6933, val_accuracy: 0.5375
2024-12-18 19:00:55,243 [INFO]: Epoch 500/500: loss: 0.6847, accuracy: 0.8792, val_loss: 0.6849, val_accuracy: 0.8500
2024-12-18 19:00:56,715 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=BGD, Layers=3...
2024-12-18 19:00:57,045 [INFO]: Epoch 1/500: loss: 0.7793, accuracy: 0.5000, val_loss: 0.7434, val_accuracy: 0.5375
2024-12-18 19:01:14,012 [INFO]: Epoch 500/500: loss: 0.6888, accuracy: 0.8542, val_loss: 0.6887, val_accuracy: 0.8750
2024-12-18 19:01:15,501 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=MBGD, Layers=1...
2024-12-18 19:01:15,817 [INFO]: Epoch 1/500: loss: 0.7215, accuracy: 0.5000, val_loss: 0.7279, val_accuracy: 0.4625
2024-12-18 19:01:35,573 [INFO]: Epoch 500/500: loss: 0.2987, accuracy: 0.8458, val_loss: 0.3175, val_accuracy: 0.8500
2024-12-18 19:01:37,246 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=MBGD, Layers=2...
2024-12-18 19:01:37,585 [INFO]: Epoch 1/500: loss: 0.7505, accuracy: 0.5000, val_loss: 0.7165, val_accuracy: 0.5375
2024-12-18 19:01:57,351 [INFO]: Epoch 500/500: loss: 0.4763, accuracy: 0.8083, val_loss: 0.4763, val_accuracy: 0.8000
2024-12-18 19:01:59,309 [INFO]: Training ANN: LR=0.01, Epochs=500, Optimizer=MBGD, Layers=3...
2024-12-18 19:01:59,674 [INFO]: Epoch 1/500: loss: 0.7065, accuracy: 0.5000, val_loss: 0.7140, val_accuracy: 0.4625
2024-12-18 19:02:19,509 [INFO]: Epoch 500/500: loss: 0.6748, accuracy: 0.7792, val_loss: 0.6745, val_accuracy: 0.7625
2024-12-18 19:02:21,479 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=SGD, Layers=1...
2024-12-18 19:02:21,888 [INFO]: Epoch 1/1000: loss: 0.6779, accuracy: 0.6208, val_loss: 0.6512, val_accuracy: 0.8000
2024-12-18 19:05:06,664 [INFO]: Epoch 1000/1000: loss: 0.1770, accuracy: 0.9208, val_loss: 0.2105, val_accuracy: 0.8875
2024-12-18 19:05:08,619 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=SGD, Layers=2...
2024-12-18 19:05:09,058 [INFO]: Epoch 1/1000: loss: 0.7235, accuracy: 0.4750, val_loss: 0.6857, val_accuracy: 0.5375
2024-12-18 19:07:56,324 [INFO]: Epoch 1000/1000: loss: 0.0045, accuracy: 1.0000, val_loss: 0.0066, val_accuracy: 1.0000
2024-12-18 19:07:58,271 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=SGD, Layers=3...
2024-12-18 19:07:58,730 [INFO]: Epoch 1/1000: loss: 0.7150, accuracy: 0.4833, val_loss: 0.6926, val_accuracy: 0.4625
2024-12-18 19:10:49,337 [INFO]: Epoch 1000/1000: loss: 0.0022, accuracy: 1.0000, val_loss: 0.0033, val_accuracy: 1.0000
2024-12-18 19:10:51,565 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=BGD, Layers=1...
2024-12-18 19:10:51,851 [INFO]: Epoch 1/1000: loss: 1.0654, accuracy: 0.5000, val_loss: 0.9864, val_accuracy: 0.5375
2024-12-18 19:11:25,915 [INFO]: Epoch 1000/1000: loss: 0.5011, accuracy: 0.8208, val_loss: 0.5017, val_accuracy: 0.8125
2024-12-18 19:11:28,458 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=BGD, Layers=2...
2024-12-18 19:11:28,787 [INFO]: Epoch 1/1000: loss: 0.6903, accuracy: 0.5000, val_loss: 0.6890, val_accuracy: 0.5375
2024-12-18 19:12:04,426 [INFO]: Epoch 1000/1000: loss: 0.6559, accuracy: 0.8000, val_loss: 0.6556, val_accuracy: 0.8000
2024-12-18 19:12:06,550 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=BGD, Layers=3...
2024-12-18 19:12:06,899 [INFO]: Epoch 1/1000: loss: 0.7683, accuracy: 0.5000, val_loss: 0.7362, val_accuracy: 0.5375
2024-12-18 19:12:41,845 [INFO]: Epoch 1000/1000: loss: 0.6926, accuracy: 0.7083, val_loss: 0.6926, val_accuracy: 0.7000
2024-12-18 19:12:43,994 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=MBGD, Layers=1...
2024-12-18 19:12:44,334 [INFO]: Epoch 1/1000: loss: 0.7882, accuracy: 0.5000, val_loss: 0.7968, val_accuracy: 0.4625
2024-12-18 19:13:24,709 [INFO]: Epoch 1000/1000: loss: 0.2495, accuracy: 0.8792, val_loss: 0.2798, val_accuracy: 0.8625
2024-12-18 19:13:26,776 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=MBGD, Layers=2...
2024-12-18 19:13:27,137 [INFO]: Epoch 1/1000: loss: 1.0441, accuracy: 0.5000, val_loss: 0.9232, val_accuracy: 0.5375
2024-12-18 19:14:07,410 [INFO]: Epoch 1000/1000: loss: 0.2796, accuracy: 0.8542, val_loss: 0.3047, val_accuracy: 0.8500
2024-12-18 19:14:09,524 [INFO]: Training ANN: LR=0.01, Epochs=1000, Optimizer=MBGD, Layers=3...
2024-12-18 19:14:09,904 [INFO]: Epoch 1/1000: loss: 0.6924, accuracy: 0.5000, val_loss: 0.6955, val_accuracy: 0.4625
2024-12-18 19:14:50,110 [INFO]: Epoch 1000/1000: loss: 0.5914, accuracy: 0.7958, val_loss: 0.5901, val_accuracy: 0.7875
2024-12-18 19:14:52,249 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=SGD, Layers=1...
2024-12-18 19:14:52,666 [INFO]: Epoch 1/50: loss: 0.5464, accuracy: 0.7333, val_loss: 0.3984, val_accuracy: 0.8000
2024-12-18 19:15:00,997 [INFO]: Epoch 50/50: loss: 0.2511, accuracy: 0.8792, val_loss: 0.2764, val_accuracy: 0.8750
2024-12-18 19:15:03,068 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=SGD, Layers=2...
2024-12-18 19:15:03,519 [INFO]: Epoch 1/50: loss: 0.7240, accuracy: 0.5167, val_loss: 0.6370, val_accuracy: 0.4625
2024-12-18 19:15:11,981 [INFO]: Epoch 50/50: loss: 0.2270, accuracy: 0.8833, val_loss: 0.2663, val_accuracy: 0.8625
2024-12-18 19:15:14,130 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=SGD, Layers=3...
2024-12-18 19:15:14,601 [INFO]: Epoch 1/50: loss: 0.7563, accuracy: 0.5083, val_loss: 0.7324, val_accuracy: 0.5375
2024-12-18 19:15:23,158 [INFO]: Epoch 50/50: loss: 0.2387, accuracy: 0.8958, val_loss: 0.2868, val_accuracy: 0.8875
2024-12-18 19:15:25,276 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=BGD, Layers=1...
2024-12-18 19:15:25,555 [INFO]: Epoch 1/50: loss: 0.7047, accuracy: 0.5000, val_loss: 0.7032, val_accuracy: 0.5000
2024-12-18 19:15:27,260 [INFO]: Epoch 50/50: loss: 0.5955, accuracy: 0.7708, val_loss: 0.5924, val_accuracy: 0.7625
2024-12-18 19:15:29,338 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=BGD, Layers=2...
2024-12-18 19:15:29,649 [INFO]: Epoch 1/50: loss: 0.7037, accuracy: 0.5000, val_loss: 0.7045, val_accuracy: 0.4625
2024-12-18 19:15:31,373 [INFO]: Epoch 50/50: loss: 0.6722, accuracy: 0.8417, val_loss: 0.6714, val_accuracy: 0.8250
2024-12-18 19:15:33,444 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=BGD, Layers=3...
2024-12-18 19:15:33,763 [INFO]: Epoch 1/50: loss: 0.7119, accuracy: 0.5000, val_loss: 0.6928, val_accuracy: 0.5375
2024-12-18 19:15:35,499 [INFO]: Epoch 50/50: loss: 0.6922, accuracy: 0.8375, val_loss: 0.6922, val_accuracy: 0.8500
2024-12-18 19:15:37,573 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=MBGD, Layers=1...
2024-12-18 19:15:37,892 [INFO]: Epoch 1/50: loss: 0.6941, accuracy: 0.5000, val_loss: 0.6703, val_accuracy: 0.8500
2024-12-18 19:15:39,910 [INFO]: Epoch 50/50: loss: 0.2991, accuracy: 0.8500, val_loss: 0.3159, val_accuracy: 0.8500
2024-12-18 19:15:41,985 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=MBGD, Layers=2...
2024-12-18 19:15:42,724 [INFO]: Epoch 1/50: loss: 1.0650, accuracy: 0.5000, val_loss: 0.6951, val_accuracy: 0.5375
2024-12-18 19:15:44,970 [INFO]: Epoch 50/50: loss: 0.4674, accuracy: 0.8250, val_loss: 0.4654, val_accuracy: 0.8250
2024-12-18 19:15:47,100 [INFO]: Training ANN: LR=0.1, Epochs=50, Optimizer=MBGD, Layers=3...
2024-12-18 19:15:47,494 [INFO]: Epoch 1/50: loss: 0.7023, accuracy: 0.5000, val_loss: 0.6906, val_accuracy: 0.5375
2024-12-18 19:15:49,607 [INFO]: Epoch 50/50: loss: 0.6665, accuracy: 0.6750, val_loss: 0.6596, val_accuracy: 0.7625
2024-12-18 19:15:51,797 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=SGD, Layers=1...
2024-12-18 19:15:52,219 [INFO]: Epoch 1/250: loss: 0.5395, accuracy: 0.7083, val_loss: 0.3768, val_accuracy: 0.8125
2024-12-18 19:16:34,378 [INFO]: Epoch 250/250: loss: 0.0070, accuracy: 1.0000, val_loss: 0.0104, val_accuracy: 1.0000
2024-12-18 19:16:36,513 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=SGD, Layers=2...
2024-12-18 19:16:36,970 [INFO]: Epoch 1/250: loss: 0.7382, accuracy: 0.4875, val_loss: 0.7518, val_accuracy: 0.4625
2024-12-18 19:17:19,812 [INFO]: Epoch 250/250: loss: 0.1689, accuracy: 0.9167, val_loss: 0.1948, val_accuracy: 0.9000
2024-12-18 19:17:22,004 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=SGD, Layers=3...
2024-12-18 19:17:22,486 [INFO]: Epoch 1/250: loss: 0.7716, accuracy: 0.4542, val_loss: 0.6894, val_accuracy: 0.5375
2024-12-18 19:18:05,996 [INFO]: Epoch 250/250: loss: 0.0032, accuracy: 1.0000, val_loss: 0.0049, val_accuracy: 1.0000
2024-12-18 19:18:08,137 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=BGD, Layers=1...
2024-12-18 19:18:08,426 [INFO]: Epoch 1/250: loss: 0.7701, accuracy: 0.5000, val_loss: 0.7186, val_accuracy: 0.5375
2024-12-18 19:18:17,006 [INFO]: Epoch 250/250: loss: 0.3687, accuracy: 0.8208, val_loss: 0.3760, val_accuracy: 0.8375
2024-12-18 19:18:19,088 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=BGD, Layers=2...
2024-12-18 19:18:19,401 [INFO]: Epoch 1/250: loss: 0.7014, accuracy: 0.5000, val_loss: 0.7043, val_accuracy: 0.4625
2024-12-18 19:18:27,944 [INFO]: Epoch 250/250: loss: 0.6383, accuracy: 0.8125, val_loss: 0.6373, val_accuracy: 0.8125
2024-12-18 19:18:30,103 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=BGD, Layers=3...
2024-12-18 19:18:30,436 [INFO]: Epoch 1/250: loss: 0.6997, accuracy: 0.5000, val_loss: 0.6915, val_accuracy: 0.5375
2024-12-18 19:18:38,968 [INFO]: Epoch 250/250: loss: 0.6866, accuracy: 0.8458, val_loss: 0.6865, val_accuracy: 0.8375
2024-12-18 19:18:41,071 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=MBGD, Layers=1...
2024-12-18 19:18:41,397 [INFO]: Epoch 1/250: loss: 0.6942, accuracy: 0.5125, val_loss: 0.6619, val_accuracy: 0.7000
2024-12-18 19:18:51,375 [INFO]: Epoch 250/250: loss: 0.2306, accuracy: 0.8958, val_loss: 0.2717, val_accuracy: 0.8625
2024-12-18 19:18:53,481 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=MBGD, Layers=2...
2024-12-18 19:18:53,829 [INFO]: Epoch 1/250: loss: 0.6938, accuracy: 0.4833, val_loss: 0.6859, val_accuracy: 0.5375
2024-12-18 19:19:03,811 [INFO]: Epoch 250/250: loss: 0.2331, accuracy: 0.8917, val_loss: 0.2763, val_accuracy: 0.8750
2024-12-18 19:19:05,956 [INFO]: Training ANN: LR=0.1, Epochs=250, Optimizer=MBGD, Layers=3...
2024-12-18 19:19:06,326 [INFO]: Epoch 1/250: loss: 0.7165, accuracy: 0.5000, val_loss: 0.6981, val_accuracy: 0.4625
2024-12-18 19:19:16,347 [INFO]: Epoch 250/250: loss: 0.2393, accuracy: 0.8917, val_loss: 0.2776, val_accuracy: 0.8750
2024-12-18 19:19:18,449 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=SGD, Layers=1...
2024-12-18 19:19:18,871 [INFO]: Epoch 1/500: loss: 0.5294, accuracy: 0.7125, val_loss: 0.3558, val_accuracy: 0.8375
2024-12-18 19:20:42,405 [INFO]: Epoch 500/500: loss: 0.0022, accuracy: 1.0000, val_loss: 0.0034, val_accuracy: 1.0000
2024-12-18 19:20:44,367 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=SGD, Layers=2...
2024-12-18 19:20:44,804 [INFO]: Epoch 1/500: loss: 0.7176, accuracy: 0.5042, val_loss: 0.5924, val_accuracy: 0.8000
2024-12-18 19:22:08,741 [INFO]: Epoch 500/500: loss: 0.0004, accuracy: 1.0000, val_loss: 0.0006, val_accuracy: 1.0000
2024-12-18 19:22:10,711 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=SGD, Layers=3...
2024-12-18 19:22:11,175 [INFO]: Epoch 1/500: loss: 0.7375, accuracy: 0.5417, val_loss: 0.6874, val_accuracy: 0.5375
2024-12-18 19:23:35,899 [INFO]: Epoch 500/500: loss: 0.0002, accuracy: 1.0000, val_loss: 0.0003, val_accuracy: 1.0000
2024-12-18 19:23:37,904 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=BGD, Layers=1...
2024-12-18 19:23:38,180 [INFO]: Epoch 1/500: loss: 0.7173, accuracy: 0.5000, val_loss: 0.6872, val_accuracy: 0.5375
2024-12-18 19:23:54,976 [INFO]: Epoch 500/500: loss: 0.2929, accuracy: 0.8500, val_loss: 0.3131, val_accuracy: 0.8500
2024-12-18 19:23:57,434 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=BGD, Layers=2...
2024-12-18 19:23:57,759 [INFO]: Epoch 1/500: loss: 0.6901, accuracy: 0.5000, val_loss: 0.6909, val_accuracy: 0.4625
2024-12-18 19:24:15,371 [INFO]: Epoch 500/500: loss: 0.4070, accuracy: 0.8167, val_loss: 0.4109, val_accuracy: 0.8000
2024-12-18 19:24:17,386 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=BGD, Layers=3...
2024-12-18 19:24:17,724 [INFO]: Epoch 1/500: loss: 0.6957, accuracy: 0.5000, val_loss: 0.6902, val_accuracy: 0.5375
2024-12-18 19:24:35,069 [INFO]: Epoch 500/500: loss: 0.6506, accuracy: 0.8208, val_loss: 0.6501, val_accuracy: 0.8125
2024-12-18 19:24:37,060 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=MBGD, Layers=1...
2024-12-18 19:24:37,392 [INFO]: Epoch 1/500: loss: 0.6963, accuracy: 0.5583, val_loss: 0.6799, val_accuracy: 0.7500
2024-12-18 19:24:57,434 [INFO]: Epoch 500/500: loss: 0.2286, accuracy: 0.8958, val_loss: 0.2742, val_accuracy: 0.8750
2024-12-18 19:24:59,403 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=MBGD, Layers=2...
2024-12-18 19:24:59,752 [INFO]: Epoch 1/500: loss: 0.7279, accuracy: 0.5000, val_loss: 0.6871, val_accuracy: 0.5375
2024-12-18 19:25:19,790 [INFO]: Epoch 500/500: loss: 0.2320, accuracy: 0.8958, val_loss: 0.2770, val_accuracy: 0.8750
2024-12-18 19:25:21,748 [INFO]: Training ANN: LR=0.1, Epochs=500, Optimizer=MBGD, Layers=3...
2024-12-18 19:25:22,122 [INFO]: Epoch 1/500: loss: 0.8059, accuracy: 0.5000, val_loss: 0.6920, val_accuracy: 0.5375
2024-12-18 19:25:42,178 [INFO]: Epoch 500/500: loss: 0.2333, accuracy: 0.8917, val_loss: 0.2789, val_accuracy: 0.8750
2024-12-18 19:25:44,160 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=SGD, Layers=1...
2024-12-18 19:25:44,579 [INFO]: Epoch 1/1000: loss: 0.5359, accuracy: 0.7208, val_loss: 0.5169, val_accuracy: 0.7875
2024-12-18 19:28:30,442 [INFO]: Epoch 1000/1000: loss: 0.0007, accuracy: 1.0000, val_loss: 0.0010, val_accuracy: 1.0000
2024-12-18 19:28:32,426 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=SGD, Layers=2...
2024-12-18 19:28:32,867 [INFO]: Epoch 1/1000: loss: 0.7552, accuracy: 0.5208, val_loss: 0.8438, val_accuracy: 0.5375
2024-12-18 19:31:20,629 [INFO]: Epoch 1000/1000: loss: 0.0002, accuracy: 1.0000, val_loss: 0.0002, val_accuracy: 1.0000
2024-12-18 19:31:22,604 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=SGD, Layers=3...
2024-12-18 19:31:23,073 [INFO]: Epoch 1/1000: loss: 0.7592, accuracy: 0.5000, val_loss: 0.7121, val_accuracy: 0.5375
2024-12-18 19:34:13,625 [INFO]: Epoch 1000/1000: loss: 0.0001, accuracy: 1.0000, val_loss: 0.0002, val_accuracy: 1.0000
2024-12-18 19:34:15,615 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=BGD, Layers=1...
2024-12-18 19:34:15,890 [INFO]: Epoch 1/1000: loss: 0.6672, accuracy: 0.5000, val_loss: 0.6601, val_accuracy: 0.5375
2024-12-18 19:34:49,420 [INFO]: Epoch 1000/1000: loss: 0.2381, accuracy: 0.8875, val_loss: 0.2727, val_accuracy: 0.8625
2024-12-18 19:34:51,366 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=BGD, Layers=2...
2024-12-18 19:34:51,661 [INFO]: Epoch 1/1000: loss: 0.7417, accuracy: 0.5000, val_loss: 0.7084, val_accuracy: 0.5375
2024-12-18 19:35:25,188 [INFO]: Epoch 1000/1000: loss: 0.2521, accuracy: 0.8792, val_loss: 0.2849, val_accuracy: 0.8500
2024-12-18 19:35:27,154 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=BGD, Layers=3...
2024-12-18 19:35:27,481 [INFO]: Epoch 1/1000: loss: 0.7125, accuracy: 0.5000, val_loss: 0.6929, val_accuracy: 0.5375
2024-12-18 19:36:01,078 [INFO]: Epoch 1000/1000: loss: 0.4651, accuracy: 0.8083, val_loss: 0.4654, val_accuracy: 0.7875
2024-12-18 19:36:03,054 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=MBGD, Layers=1...
2024-12-18 19:36:03,366 [INFO]: Epoch 1/1000: loss: 0.7390, accuracy: 0.5042, val_loss: 0.6804, val_accuracy: 0.5250
2024-12-18 19:36:42,618 [INFO]: Epoch 1000/1000: loss: 0.2283, accuracy: 0.8917, val_loss: 0.2733, val_accuracy: 0.8750
2024-12-18 19:36:44,568 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=MBGD, Layers=2...
2024-12-18 19:36:44,911 [INFO]: Epoch 1/1000: loss: 0.7373, accuracy: 0.5000, val_loss: 0.6814, val_accuracy: 0.8500
2024-12-18 19:37:24,343 [INFO]: Epoch 1000/1000: loss: 0.2176, accuracy: 0.9042, val_loss: 0.2590, val_accuracy: 0.8750
2024-12-18 19:37:26,308 [INFO]: Training ANN: LR=0.1, Epochs=1000, Optimizer=MBGD, Layers=3...
2024-12-18 19:37:26,670 [INFO]: Epoch 1/1000: loss: 0.6958, accuracy: 0.4667, val_loss: 0.6922, val_accuracy: 0.5375
2024-12-18 19:38:06,218 [INFO]: Epoch 1000/1000: loss: 0.2345, accuracy: 0.8917, val_loss: 0.2796, val_accuracy: 0.8750
2024-12-18 19:38:08,204 [INFO]: ANN training complete.
2024-12-18 19:38:08,204 [INFO]: Training SVM: Kernel=linear, C=0.01, Degree=3, Gamma=scale...
2024-12-18 19:38:09,232 [INFO]: Training SVM: Kernel=linear, C=0.1, Degree=3, Gamma=scale...
2024-12-18 19:38:10,658 [INFO]: Training SVM: Kernel=linear, C=1, Degree=3, Gamma=scale...
2024-12-18 19:38:11,638 [INFO]: Training SVM: Kernel=linear, C=10, Degree=3, Gamma=scale...
2024-12-18 19:38:12,738 [INFO]: Training SVM: Kernel=linear, C=100, Degree=3, Gamma=scale...
2024-12-18 19:38:13,776 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=2, Gamma=scale...
2024-12-18 19:38:14,809 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=2, Gamma=auto...
2024-12-18 19:38:15,861 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=3, Gamma=scale...
2024-12-18 19:38:16,917 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=3, Gamma=auto...
2024-12-18 19:38:18,012 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=4, Gamma=scale...
2024-12-18 19:38:19,071 [INFO]: Training SVM: Kernel=poly, C=0.01, Degree=4, Gamma=auto...
2024-12-18 19:38:20,100 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=2, Gamma=scale...
2024-12-18 19:38:21,124 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=2, Gamma=auto...
2024-12-18 19:38:22,189 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=3, Gamma=scale...
2024-12-18 19:38:23,240 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=3, Gamma=auto...
2024-12-18 19:38:24,288 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=4, Gamma=scale...
2024-12-18 19:38:25,300 [INFO]: Training SVM: Kernel=poly, C=0.1, Degree=4, Gamma=auto...
2024-12-18 19:38:26,323 [INFO]: Training SVM: Kernel=poly, C=1, Degree=2, Gamma=scale...
2024-12-18 19:38:27,378 [INFO]: Training SVM: Kernel=poly, C=1, Degree=2, Gamma=auto...
2024-12-18 19:38:28,474 [INFO]: Training SVM: Kernel=poly, C=1, Degree=3, Gamma=scale...
2024-12-18 19:38:29,477 [INFO]: Training SVM: Kernel=poly, C=1, Degree=3, Gamma=auto...
2024-12-18 19:38:30,472 [INFO]: Training SVM: Kernel=poly, C=1, Degree=4, Gamma=scale...
2024-12-18 19:38:31,490 [INFO]: Training SVM: Kernel=poly, C=1, Degree=4, Gamma=auto...
2024-12-18 19:38:32,620 [INFO]: Training SVM: Kernel=poly, C=10, Degree=2, Gamma=scale...
2024-12-18 19:38:33,698 [INFO]: Training SVM: Kernel=poly, C=10, Degree=2, Gamma=auto...
2024-12-18 19:38:34,715 [INFO]: Training SVM: Kernel=poly, C=10, Degree=3, Gamma=scale...
2024-12-18 19:38:35,690 [INFO]: Training SVM: Kernel=poly, C=10, Degree=3, Gamma=auto...
2024-12-18 19:38:36,671 [INFO]: Training SVM: Kernel=poly, C=10, Degree=4, Gamma=scale...
2024-12-18 19:38:37,762 [INFO]: Training SVM: Kernel=poly, C=10, Degree=4, Gamma=auto...
2024-12-18 19:38:38,826 [INFO]: Training SVM: Kernel=rbf, C=0.01, Degree=3, Gamma=scale...
2024-12-18 19:38:39,996 [INFO]: Training SVM: Kernel=rbf, C=0.01, Degree=3, Gamma=auto...
2024-12-18 19:38:41,152 [INFO]: Training SVM: Kernel=rbf, C=0.01, Degree=3, Gamma=0.01...
2024-12-18 19:38:42,308 [INFO]: Training SVM: Kernel=rbf, C=0.01, Degree=3, Gamma=0.1...
2024-12-18 19:38:43,528 [INFO]: Training SVM: Kernel=rbf, C=0.01, Degree=3, Gamma=1...
2024-12-18 19:38:44,710 [INFO]: Training SVM: Kernel=rbf, C=0.1, Degree=3, Gamma=scale...
2024-12-18 19:38:45,761 [INFO]: Training SVM: Kernel=rbf, C=0.1, Degree=3, Gamma=auto...
2024-12-18 19:38:46,820 [INFO]: Training SVM: Kernel=rbf, C=0.1, Degree=3, Gamma=0.01...
2024-12-18 19:38:48,034 [INFO]: Training SVM: Kernel=rbf, C=0.1, Degree=3, Gamma=0.1...
2024-12-18 19:38:49,177 [INFO]: Training SVM: Kernel=rbf, C=0.1, Degree=3, Gamma=1...
2024-12-18 19:38:50,232 [INFO]: Training SVM: Kernel=rbf, C=1, Degree=3, Gamma=scale...
2024-12-18 19:38:51,218 [INFO]: Training SVM: Kernel=rbf, C=1, Degree=3, Gamma=auto...
2024-12-18 19:38:54,724 [INFO]: Training SVM: Kernel=rbf, C=1, Degree=3, Gamma=0.01...
2024-12-18 19:38:58,071 [INFO]: Training SVM: Kernel=rbf, C=1, Degree=3, Gamma=0.1...
2024-12-18 19:39:02,201 [INFO]: Training SVM: Kernel=rbf, C=1, Degree=3, Gamma=1...
2024-12-18 19:39:06,366 [INFO]: Training SVM: Kernel=rbf, C=10, Degree=3, Gamma=scale...
2024-12-18 19:39:10,543 [INFO]: Training SVM: Kernel=rbf, C=10, Degree=3, Gamma=auto...
2024-12-18 19:39:13,851 [INFO]: Training SVM: Kernel=rbf, C=10, Degree=3, Gamma=0.01...
2024-12-18 19:39:17,004 [INFO]: Training SVM: Kernel=rbf, C=10, Degree=3, Gamma=0.1...
2024-12-18 19:39:21,238 [INFO]: Training SVM: Kernel=rbf, C=10, Degree=3, Gamma=1...
2024-12-18 19:39:24,670 [INFO]: Training SVM: Kernel=rbf, C=100, Degree=3, Gamma=scale...
2024-12-18 19:39:27,758 [INFO]: Training SVM: Kernel=rbf, C=100, Degree=3, Gamma=auto...
2024-12-18 19:39:31,921 [INFO]: Training SVM: Kernel=rbf, C=100, Degree=3, Gamma=0.01...
2024-12-18 19:39:35,314 [INFO]: Training SVM: Kernel=rbf, C=100, Degree=3, Gamma=0.1...
2024-12-18 19:39:38,578 [INFO]: Training SVM: Kernel=rbf, C=100, Degree=3, Gamma=1...
2024-12-18 19:39:42,611 [INFO]: SVM training complete.
2024-12-18 19:39:42,611 [INFO]: 
Saving combined metrics...
2024-12-18 19:39:42,612 [INFO]: Combined metrics saved to train_results/combined_metrics.txt.
